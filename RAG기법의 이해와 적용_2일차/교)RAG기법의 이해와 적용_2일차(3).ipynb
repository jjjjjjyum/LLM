{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸŒ¼ RAGê¸°ë²•ì˜ ì´í•´ì™€ ì ìš©(3) - 2ì°¨ì‹œ(24.11.29)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "LangChainProject\n"
     ]
    }
   ],
   "source": [
    "logging.langsmith('LangChainProject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template('{country}ì— ëŒ€í•´ 300ì ì´ë‚´ë¡œ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì¤˜')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì€ ë™ì•„ì‹œì•„ì— ìœ„ì¹˜í•œ ë°˜ë„ êµ­ê°€ë¡œ, ê³µì‹ ëª…ì¹­ì€ ëŒ€í•œë¯¼êµ­ì…ë‹ˆë‹¤. ìˆ˜ë„ëŠ” ì„œìš¸ì´ë©°, ì¸êµ¬ëŠ” ì•½ 5,100ë§Œ ëª…ì…ë‹ˆë‹¤. í•œêµ­ì€ ì—­ì‚¬ì ìœ¼ë¡œ ê³ ëŒ€ ì‚¼êµ­ ì‹œëŒ€, ê³ ë ¤, ì¡°ì„  ì™•ì¡° ë“±ì„ ê±°ì¹˜ë©° ë°œì „í•´ì™”ìŠµë‹ˆë‹¤. í˜„ëŒ€ì—ëŠ” ê¸°ìˆ ê³¼ ë¬¸í™”ì˜ ì¤‘ì‹¬ì§€ë¡œ, íŠ¹íˆ K-pop, ë“œë¼ë§ˆ ë“± í•œë¥˜ ë¬¸í™”ê°€ ì„¸ê³„ì ìœ¼ë¡œ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. ê²½ì œì ìœ¼ë¡œëŠ” ë°˜ë„ì²´, ìë™ì°¨, ì¡°ì„ ì—… ë“±ì´ ì£¼ìš” ì‚°ì—…ì…ë‹ˆë‹¤. ì •ì¹˜ ì²´ì œëŠ” ë¯¼ì£¼ê³µí™”êµ­ì´ë©°, ë‚¨ë¶ìœ¼ë¡œ ë¶„ë‹¨ë˜ì–´ ìˆì–´ ë¶í•œê³¼ì˜ ê´€ê³„ê°€ ì¤‘ìš”í•œ ì™¸êµ ì´ìŠˆì…ë‹ˆë‹¤.\n",
      "CPU times: total: 203 ms\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country' : 'í•œêµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ì¶œë ¥ ì†ë„ë¥¼ ë¹ ë¥´ê²Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(InMemoryCache())\n",
    "# ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ê³¼ ì‘ë‹µ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥ => ë™ì¼í•œ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ê²°ê³¼ë¥¼ ì¬ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì€ ë™ì•„ì‹œì•„ì— ìœ„ì¹˜í•œ ë‚˜ë¼ë¡œ, ê³µì‹ì ìœ¼ë¡œëŠ” ëŒ€í•œë¯¼êµ­ì´ë¼ê³  ë¶ˆë¦½ë‹ˆë‹¤. ì„œìš¸ì´ ìˆ˜ë„ì´ë©°, í•œë°˜ë„ì˜ ë‚¨ìª½ì— ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤. ê³ ëŒ€ì—ëŠ” ê³ ì¡°ì„ ê³¼ ì‚¼êµ­ì‹œëŒ€, ê³ ë ¤, ì¡°ì„  ë“±ì˜ ì™•ì¡°ê°€ ìˆì—ˆê³ , í˜„ëŒ€ì—ëŠ” 1948ë…„ ëŒ€í•œë¯¼êµ­ ì •ë¶€ê°€ ìˆ˜ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤. ê²½ì œëŠ” ê¸°ìˆ ê³¼ ì œì¡°ì—… ì¤‘ì‹¬ìœ¼ë¡œ ë°œì „í–ˆìœ¼ë©°, í˜„ëŒ€ ë¬¸í™”, íŠ¹íˆ K-íŒê³¼ ë“œë¼ë§ˆê°€ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. ì •ì¹˜ ì²´ì œëŠ” ë¯¼ì£¼ ê³µí™”êµ­ì´ë©°, ë‚¨ë¶í•œ ë¬¸ì œë¡œ ì¸í•´ ì—¬ì „íˆ êµ°ì‚¬ì  ê¸´ì¥ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country' : 'í•œêµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì€ ë™ì•„ì‹œì•„ì— ìœ„ì¹˜í•œ ë‚˜ë¼ë¡œ, ê³µì‹ì ìœ¼ë¡œëŠ” ëŒ€í•œë¯¼êµ­ì´ë¼ê³  ë¶ˆë¦½ë‹ˆë‹¤. ì„œìš¸ì´ ìˆ˜ë„ì´ë©°, í•œë°˜ë„ì˜ ë‚¨ìª½ì— ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤. ê³ ëŒ€ì—ëŠ” ê³ ì¡°ì„ ê³¼ ì‚¼êµ­ì‹œëŒ€, ê³ ë ¤, ì¡°ì„  ë“±ì˜ ì™•ì¡°ê°€ ìˆì—ˆê³ , í˜„ëŒ€ì—ëŠ” 1948ë…„ ëŒ€í•œë¯¼êµ­ ì •ë¶€ê°€ ìˆ˜ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤. ê²½ì œëŠ” ê¸°ìˆ ê³¼ ì œì¡°ì—… ì¤‘ì‹¬ìœ¼ë¡œ ë°œì „í–ˆìœ¼ë©°, í˜„ëŒ€ ë¬¸í™”, íŠ¹íˆ K-íŒê³¼ ë“œë¼ë§ˆê°€ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. ì •ì¹˜ ì²´ì œëŠ” ë¯¼ì£¼ ê³µí™”êµ­ì´ë©°, ë‚¨ë¶í•œ ë¬¸ì œë¡œ ì¸í•´ ì—¬ì „íˆ êµ°ì‚¬ì  ê¸´ì¥ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4.04 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country' : 'í•œêµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.cache import SQLiteCache\n",
    "# ì˜êµ¬ì  ë°ì´í„° ì‚¬ìš© ê°€ëŠ¥\n",
    "# íŒŒì¼ì„ ì‚­ì œí•˜ê±°ë‚˜ ìƒˆë¡œìš´ ê²½ë¡œ ì‚¬ìš©ì‹œ ë¦¬ì…‹\n",
    "from langchain_core.globals import set_llm_cache\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('cache'):\n",
    "    os.makedirs('cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(SQLiteCache(database_path='cache/llm_cache.db'))\n",
    "# ì˜êµ¬ì  ì €ì¥ê°€ëŠ¥í•œ SQL DB ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ¤í˜ì¸ì€ ìœ ëŸ½ ë‚¨ì„œë¶€ì— ìœ„ì¹˜í•œ ì…í—Œêµ°ì£¼êµ­ìœ¼ë¡œ, ìˆ˜ë„ëŠ” ë§ˆë“œë¦¬ë“œì…ë‹ˆë‹¤. ì´ë² ë¦¬ì•„ ë°˜ë„ë¥¼ ì°¨ì§€í•˜ê³  ìˆìœ¼ë©°, í¬ë¥´íˆ¬ê°ˆê³¼ êµ­ê²½ì„ ì ‘í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìŠ¤í˜ì¸ì€ ë‹¤ì–‘í•œ ë¬¸í™”ì™€ ì—­ì‚¬ë¥¼ ì§€ë‹ˆê³  ìˆìœ¼ë©°, í”Œë¼ë©©ì½”ì™€ íˆ¬ìš°, ê±´ì¶•ë¬¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. ì£¼ìš” ì–¸ì–´ëŠ” ìŠ¤í˜ì¸ì–´ì´ë©°, ê²½ì œëŠ” ê´€ê´‘ì—…, ë†ì—…, ì œì¡°ì—…ì´ ì¤‘ì‹¬ì…ë‹ˆë‹¤. ìœ ëŸ½ì—°í•©(EU)ê³¼ ìœ ë¡œì¡´ì˜ ì¼ì›ìœ¼ë¡œ ì •ì¹˜, ê²½ì œì ìœ¼ë¡œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country':'ìŠ¤í˜ì¸'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ¤í˜ì¸ì€ ìœ ëŸ½ ë‚¨ì„œë¶€ì— ìœ„ì¹˜í•œ ì…í—Œêµ°ì£¼êµ­ìœ¼ë¡œ, ìˆ˜ë„ëŠ” ë§ˆë“œë¦¬ë“œì…ë‹ˆë‹¤. ì´ë² ë¦¬ì•„ ë°˜ë„ë¥¼ ì°¨ì§€í•˜ê³  ìˆìœ¼ë©°, í¬ë¥´íˆ¬ê°ˆê³¼ êµ­ê²½ì„ ì ‘í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìŠ¤í˜ì¸ì€ ë‹¤ì–‘í•œ ë¬¸í™”ì™€ ì—­ì‚¬ë¥¼ ì§€ë‹ˆê³  ìˆìœ¼ë©°, í”Œë¼ë©©ì½”ì™€ íˆ¬ìš°, ê±´ì¶•ë¬¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤. ì£¼ìš” ì–¸ì–´ëŠ” ìŠ¤í˜ì¸ì–´ì´ë©°, ê²½ì œëŠ” ê´€ê´‘ì—…, ë†ì—…, ì œì¡°ì—…ì´ ì¤‘ì‹¬ì…ë‹ˆë‹¤. ìœ ëŸ½ì—°í•©(EU)ê³¼ ìœ ë¡œì¡´ì˜ ì¼ì›ìœ¼ë¡œ ì •ì¹˜, ê²½ì œì ìœ¼ë¡œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country':'ìŠ¤í˜ì¸'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'cache/llm_cache.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table [('full_llm_cache',), ('full_md5_llm_cache',)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print('Table', tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"\\\\uc2a4\\\\ud398\\\\uc778\\\\uc5d0 \\\\ub300\\\\ub798 300\\\\uc790 \\\\uc774\\\\ub0b4\\\\ub85c \\\\uc694\\\\uc57d\\\\ud574\\\\uc11c \\\\uc124\\\\uba85\\\\ud574\\\\uc918\", \"type\": \"human\"}}]', '{\"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"max_retries\": 2, \"model_name\": \"gpt-4o\", \"n\": 1, \"openai_api_key\": {\"id\": [\"OPENAI_API_KEY\"], \"lc\": 1, \"type\": \"secret\"}, \"temperature\": 0.7}, \"lc\": 1, \"name\": \"ChatOpenAI\", \"type\": \"constructor\"}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output\", \"ChatGeneration\"], \"kwargs\": {\"text\": \"\\\\uc2a4\\\\ud398\\\\uc778\\\\uc740 \\\\uc720\\\\ub7fd \\\\ub0a8\\\\uc11c\\\\ubd80\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\uc785\\\\ud5cc\\\\uad70\\\\uc8fc\\\\uad6d\\\\uc73c\\\\ub85c, \\\\uc218\\\\ub3c4\\\\ub294 \\\\ub9c8\\\\ub4dc\\\\ub9ac\\\\ub4dc\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc774\\\\ubca0\\\\ub9ac\\\\uc544 \\\\ubc18\\\\ub3c4\\\\ub97c \\\\ucc28\\\\uc9c0\\\\ud558\\\\uace0 \\\\uc788\\\\uc73c\\\\uba70, \\\\ud3ec\\\\ub974\\\\ud22c\\\\uac08\\\\uacfc \\\\uad6d\\\\uacbd\\\\uc744 \\\\uc811\\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc2a4\\\\ud398\\\\uc778\\\\uc740 \\\\ub2e4\\\\uc591\\\\ud55c \\\\ubb38\\\\ud654\\\\uc640 \\\\uc5ed\\\\uc0ac\\\\ub97c \\\\uc9c0\\\\ub2c8\\\\uace0 \\\\uc788\\\\uc73c\\\\uba70, \\\\ud50c\\\\ub77c\\\\uba69\\\\ucf54\\\\uc640 \\\\ud22c\\\\uc6b0, \\\\uac74\\\\ucd95\\\\ubb3c\\\\ub85c \\\\uc720\\\\uba85\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc8fc\\\\uc694 \\\\uc5b8\\\\uc5b4\\\\ub294 \\\\uc2a4\\\\ud398\\\\uc778\\\\uc5b4\\\\uc774\\\\uba70, \\\\uacbd\\\\uc81c\\\\ub294 \\\\uad00\\\\uad11\\\\uc5c5, \\\\ub18d\\\\uc5c5, \\\\uc81c\\\\uc870\\\\uc5c5\\\\uc774 \\\\uc911\\\\uc2ec\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc720\\\\ub7fd\\\\uc5f0\\\\ud569(EU)\\\\uacfc \\\\uc720\\\\ub85c\\\\uc874\\\\uc758 \\\\uc77c\\\\uc6d0\\\\uc73c\\\\ub85c \\\\uc815\\\\uce58, \\\\uacbd\\\\uc81c\\\\uc801\\\\uc73c\\\\ub85c \\\\uc911\\\\uc694\\\\ud55c \\\\uc5ed\\\\ud560\\\\uc744 \\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"generation_info\": {\"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ChatGeneration\", \"message\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"AIMessage\"], \"kwargs\": {\"content\": \"\\\\uc2a4\\\\ud398\\\\uc778\\\\uc740 \\\\uc720\\\\ub7fd \\\\ub0a8\\\\uc11c\\\\ubd80\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\uc785\\\\ud5cc\\\\uad70\\\\uc8fc\\\\uad6d\\\\uc73c\\\\ub85c, \\\\uc218\\\\ub3c4\\\\ub294 \\\\ub9c8\\\\ub4dc\\\\ub9ac\\\\ub4dc\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc774\\\\ubca0\\\\ub9ac\\\\uc544 \\\\ubc18\\\\ub3c4\\\\ub97c \\\\ucc28\\\\uc9c0\\\\ud558\\\\uace0 \\\\uc788\\\\uc73c\\\\uba70, \\\\ud3ec\\\\ub974\\\\ud22c\\\\uac08\\\\uacfc \\\\uad6d\\\\uacbd\\\\uc744 \\\\uc811\\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc2a4\\\\ud398\\\\uc778\\\\uc740 \\\\ub2e4\\\\uc591\\\\ud55c \\\\ubb38\\\\ud654\\\\uc640 \\\\uc5ed\\\\uc0ac\\\\ub97c \\\\uc9c0\\\\ub2c8\\\\uace0 \\\\uc788\\\\uc73c\\\\uba70, \\\\ud50c\\\\ub77c\\\\uba69\\\\ucf54\\\\uc640 \\\\ud22c\\\\uc6b0, \\\\uac74\\\\ucd95\\\\ubb3c\\\\ub85c \\\\uc720\\\\uba85\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc8fc\\\\uc694 \\\\uc5b8\\\\uc5b4\\\\ub294 \\\\uc2a4\\\\ud398\\\\uc778\\\\uc5b4\\\\uc774\\\\uba70, \\\\uacbd\\\\uc81c\\\\ub294 \\\\uad00\\\\uad11\\\\uc5c5, \\\\ub18d\\\\uc5c5, \\\\uc81c\\\\uc870\\\\uc5c5\\\\uc774 \\\\uc911\\\\uc2ec\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc720\\\\ub7fd\\\\uc5f0\\\\ud569(EU)\\\\uacfc \\\\uc720\\\\ub85c\\\\uc874\\\\uc758 \\\\uc77c\\\\uc6d0\\\\uc73c\\\\ub85c \\\\uc815\\\\uce58, \\\\uacbd\\\\uc81c\\\\uc801\\\\uc73c\\\\ub85c \\\\uc911\\\\uc694\\\\ud55c \\\\uc5ed\\\\ud560\\\\uc744 \\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 126, \"prompt_tokens\": 25, \"total_tokens\": 151, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}, \"model_name\": \"gpt-4o-2024-08-06\", \"system_fingerprint\": \"fp_831e067d82\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"id\": \"run-19f4f3f9-3f9a-4472-8cb5-d788d243937a-0\", \"usage_metadata\": {\"input_tokens\": 25, \"output_tokens\": 126, \"total_tokens\": 151, \"input_token_details\": {\"audio\": 0, \"cache_read\": 0}, \"output_token_details\": {\"audio\": 0, \"reasoning\": 0}}, \"tool_calls\": [], \"invalid_tool_calls\": []}}}}')\n"
     ]
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM full_llm_cache')\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "# ë¬¸ì„ ì˜ ì—´ê³  ë‹«ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 24\n",
      "\tPrompt Tokens: 16\n",
      "\tCompletion Tokens: 8\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00012000000000000002\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke('ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?')\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì‚¬ìš©ëœ í† í° ìˆ˜ : 119\n",
      "í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ëœ í† í° ìˆ˜ : 18\n",
      "ë‹µë³€ì— ì‚¬ìš©ëœ í† í° ìˆ˜ : 101\n",
      "í˜¸ì¶œì— ì²­êµ¬ëœ ê¸ˆì•¡(USD): 0.001055\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke('ê¹€ê²½ì¼ êµìˆ˜ì˜ ëª…ì–¸ í•˜ë‚˜ ê°€ì ¸ì™€ì¤˜')\n",
    "    print(f'ì´ ì‚¬ìš©ëœ í† í° ìˆ˜ : {cb.total_tokens}')\n",
    "    print(f'í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ëœ í† í° ìˆ˜ : {cb.prompt_tokens}')\n",
    "    print(f'ë‹µë³€ì— ì‚¬ìš©ëœ í† í° ìˆ˜ : {cb.completion_tokens}')\n",
    "    print(f'í˜¸ì¶œì— ì²­êµ¬ëœ ê¸ˆì•¡(USD): {cb.total_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# pip install -qU langchain-community arxiv pymupdf pypdf unstructured python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/SPRi AI Brief_11ì›”í˜¸_ì‚°ì—…ë™í–¥_F.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print('[metadata]')\n",
    "        keys = []\n",
    "        for k in docs[0].metadata.keys():\n",
    "            keys.append(k)\n",
    "        print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loder = PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loder.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source', 'page']\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  2024-11ì›”í˜¸\n",
      "8\n",
      "ë©”íƒ€, ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì²˜ë¦¬í•˜ëŠ” ì²« ë©€í‹°ëª¨ë‹¬ AI ëª¨ë¸ â€˜ë¼ë§ˆ 3.2â€™ ê³µê°œnë©”íƒ€ê°€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ê³¼ ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ëŸ‰ ëª¨ë¸ì„ í¬í•¨í•˜ëŠ” ë¼ë§ˆ 3.2 ì‹œë¦¬ì¦ˆë¥¼ ê³µê°œnë¹„ì „ ê¸°ëŠ¥ì„ ê°–ì¶˜ ë¼ë§ˆ 3.2 90B ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì¸ì‹ê³¼ ì‹œê°ì  ì´í•´ ì‘ì—…ì—ì„œ ì•¤ìŠ¤ë¡œí”½ì˜ â€˜í´ë¡œë“œ3-í•˜ì´ì¿ â€™ ë° ì˜¤í”ˆAIì˜ â€˜GPT-4o-ë¯¸ë‹ˆâ€™ì™€ ëŒ€ë“±í•œ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ ë³´ìœ \n",
      "KEY Contents\n",
      "Â£ë¼ë§ˆ 3.2 90B ëª¨ë¸, ì´ë¯¸ì§€ ì¸ì‹ê³¼ ì‹œê°ì  ì´í•´ì—ì„œ GPT-4o-ë¯¸\n"
     ]
    }
   ],
   "source": [
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ 11ì›”í˜¸\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:300])\n",
    "# ì´ë¯¸ì§€í˜•íƒœì˜ í…ìŠ¤íŠ¸ëŠ” ì½ì–´ì˜¤ì§€ ëª»í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•)ê¸°ë²• ì ìš©_2ì¼ì°¨.pptx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "\n",
    "loader = UnstructuredPowerPointLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•)ê¸°ë²• ì ìš©_2ì¼ì°¨.pptx'}, page_content='RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•) ì ìš©\\n\\nDay 02\\n\\nê°•ì˜ì : ê¹€ìˆ˜ë¹ˆ\\n\\n\\n\\n1\\n\\n2\\n\\n3\\n\\nContents\\n\\nRAG\\n\\në²¡í„° DB\\n\\nLangchain\\n\\n\\n\\n1\\n\\n2\\n\\n3\\n\\n3\\n\\nLangChain\\n\\në­ì²´ì¸?\\n\\n- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” í”„ë ˆì„ì›Œí¬\\n\\nLLMê³¼ ë„êµ¬ ì—°ê²° : Vecor DB, API, íŒŒì¼ ë“±ê³¼ í†µí•©\\n\\nì‘ì—… ìë™í™” : ìë™í™”ëœ ì›Œí¬í”Œë¡œìš° êµ¬í˜„ ì§€ì›\\n\\nê²€ìƒ‰ ë° ìƒì„± ê¸°ëŠ¥ : LLMê³¼ ê²€ìƒ‰ ê¸°ë°˜ ì‹œìŠ¤í…œì„ ê²°í•©í•´ ì‘ë‹µì˜ í’ˆì§ˆ í–¥ìƒ\\n\\n\\n\\n3\\n\\nLangChain\\n\\nê¸°ëŠ¥\\n\\ní”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­, ì†Œìˆ˜ì˜ ì˜ˆì‹œ, ì‘ë‹µì— ê·¼ê±°í•œ ë‚´ìš© ë“±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë¬¸ë§¥ ì†ŒìŠ¤ì™€ ëª¨ë¸ì˜ ì—°ê²°\\n\\nâ†’ ì–¸ì–´ ëª¨ë¸ì€ ì œê³µëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.\\n\\në¬¸ë§¥ ì¸ì‹\\n\\nì–¸ì–´ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì–´ë–¤ ë‹µë³€ì„ ì œê³µí•˜ê±°ë‚˜ ì–´ë–¤ ì¡°ì·¨ë¥¼ ì·¨í•´ì•¼ í• ì§€ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆë‹¤\\n\\nâ†’ ë‹¨ìˆœíˆ ì •ë³´ ì¬ìƒì‚°ì´ ì•„ë‹ˆë¼ ì£¼ì–´ì§„ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ í•´ê²°ì±… ì œì‹œ ê°€ëŠ¥\\n\\nì¶”ë¡ \\n\\n\\n\\n3\\n\\nLangChain\\n\\nLangSmith\\n\\nLLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ, ëª¨ë‹ˆí„°ë§ ë° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í”Œë«í¼\\n\\në‹¨ìˆœíˆ ì •ë³´ ì¬ìƒì‚°ì´ ì•„ë‹ˆë¼ ì£¼ì–´ì§„ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ í•´ê²°ì±… ì œì‹œ ê°€ëŠ¥\\n\\nì¶”ì  ê¸°ëŠ¥\\n\\nì˜ˆìƒì¹˜ ëª»í•œ ìµœì¢… ê²°ê³¼, ì²´ì¸ì´ ì˜ˆìƒë³´ë‹¤ ëŠë¦° ì´ìœ  ë“±ì— ëŒ€í•´ ì¶”ì í•˜ëŠ”ë° ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤\\n\\n\\n\\n3\\n\\nLangChain\\n\\nLangSmith\\n\\nhttps://smith.langchain.com\\n\\n- ë§ˆì°¬ê°€ì§€ë¡œ í‚¤ ë°œê¸‰(â˜…â˜…â˜…â˜…â˜…â˜…ì €ì¥í•„ìˆ˜)\\n\\n- .envì— ë„£ì–´ì•¼ í•  í•­ëª©\\n\\n```\\n\\nLANGCHAIN_TRACING_V2 = true\\n\\nLANGCHAIN_ENDPOINT = https://api.langchain.com\\n\\nLANGCHAIN_API_KEY = ë°œê¸‰ë°›ì€ í‚¤\\n\\nLANGCHAIN_PROJECT = í”„ë¡œì íŠ¸ëª…\\n\\n```\\n\\n\\n\\nê°ì‚¬í•©ë‹ˆë‹¤.\\n\\nThank You')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = 'https://www.langchain.com/'\n",
    "url2 = 'https://python.langchain.com/v0.2/docs/introduction/'\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path = (url1, url2),\n",
    "    bs_kwargs = dict(\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            # í•„í„° ë„£ì–´ì£¼ê¸°\n",
    "            # class_ = ('docs-doc-page')\n",
    "            name = ('div')\n",
    "            # text = ('')\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.langchain.com/'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nLangChainLangSmithLangGraphMethods\\n\\nRetrievalAgentsEvaluationResources\\n\\nBlogCase StudiesLangChain AcademyCommunityExpertsChangelogState of AI AgentsBreakout Agent StoriesDocs\\n\\nPythonLangChainLangSmithLangGraphJavaScriptLangChainLangSmithLangGraphCompany\\n\\nAboutCareersPricing\\n\\nLangSmithLangGraph PlatformGet a demoSign up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nLangChainLangSmithLangGraphMethods\\n\\nRetrievalAgentsEvaluationResources\\n\\nBlogCase StudiesLangChain AcademyCommunityExpertsChangelogState of AI AgentsBreakout Agent StoriesDocs\\n\\nPythonLangChainLangSmithLangGraphJavaScriptLangChainLangSmithLangGraphCompany\\n\\nAboutCareersPricing\\n\\nLangSmithLangGraph PlatformGet a demoSign upLangChainâ€™s suite of products supports developers along each step of the LLM application lifecycle.Applications that can reason. Powered by LangChain.Get a demoSign up for free\\n\\nFrom startups to global enterprises, ambitious builders choose LangChain products.BuildLangChain is a composable framework to build with LLMs. LangGraph is the orchestration framework for controllable agentic workflows.RunDeploy your LLM applications at scale with LangGraph Platform, our infrastructure purpose-built for agents.ManageDebug, collaborate, test, and monitor your LLM app in LangSmith - whether it's built with a LangChain framework or not.\\xa0\\n\\n\\n\\nBuild your app with LangChainBuild context-aware, reasoning applications with LangChainâ€™s flexible framework that leverages your companyâ€™s data and APIs. Future-proof your application by making vendor optionality part of your LLM infrastructure design.Learn more about LangChain\\n\\n\\n\\n\\nRun at scale with LangGraph\\xa0PlatformUse LangGraph Platformâ€™s APIs to design agent-driven user experiences featuring human-in-the-loop, multi-agent collaboration, conversation history, long-term memory, and time-travel. Deploy with fault-tolerant scalability.\\n\\n\\nLearn more about LangGraph\\xa0Platform\\n\\nManage LLM performance with\\xa0LangSmithShip faster with LangSmithâ€™s debug, test, deploy, and monitoring workflows. Donâ€™t rely on â€œvibesâ€ â€“ add engineering rigor to your LLM-development workflow, whether youâ€™re building with LangChain or not.Learn more about LangSmith\\n\\n\\nHear from our happy customersLangChain, LangGraph, and LangSmith help teams of all sizes, across all industries - from ambitious startups to established enterprises.â€œLangSmith helped us improve the accuracy and performance of Retoolâ€™s fine-tuned models. Not only did we deliver a better product by iterating with LangSmith, but weâ€™re shipping new AI features to our users in a fraction of the time it would have taken without it.â€Jamie CuffeHead of Self-Serve and New Productsâ€œBy combining the benefits of LangSmith and standing on the shoulders of a gigantic open-source community, weâ€™re able to identify the right approaches of using LLMs in an enterprise-setting faster.â€Yusuke KajiGeneral Manager of AIâ€œWorking with LangChain and LangSmith on the Elastic AI Assistant had a significant positive impact on the overall pace and quality of the development and shipping experience. We couldnâ€™t have achieved \\xa0the product experience delivered to our customers without LangChain, and we couldnâ€™t have done it at the same pace without LangSmith.â€James SpiteriDirector of Security Productsâ€œAs soon as we heard about LangSmith, we moved our entire development stack onto it. We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.â€Jose PeÃ±aSenior Manager\\n\\n\\n\\n\\n\\n\\n\\n\\nThe reference architecture enterprises adopt for success.LangChainâ€™s suite of products can be used independently or stacked together for multiplicative impact â€“ guiding you through building, running, and managing your LLM apps.15M+Monthly Downloads100K+Apps Powered100K+GitHub Stars4K+ContributorsThe biggest developer community in GenAILearn alongside the 1M+ developers who are pushing the industry forward.Explore LangChain\\n\\n\\nGet started with the LangSmith platform todayGet a demoSign up for freeTeams building with LangChain are driving operational efficiency, increasing discovery & personalization, and delivering premium products that generate revenue.See customer stories\\n\\n\\nGet inspired by companies who have done it.Financial Services\\n\\n\\nFinTech\\n\\n\\nTechnology\\n\\n\\nLangSmith is the enterprise\\xa0developer platform\\xa0built for LLMs.Explore LangSmith\\n\\n\\n\\n\\nGain visibility to make trade offs between cost, latency, and quality.\\n\\nIncrease developer productivity.\\n\\nEliminate manual, error-prone testing.\\n\\nReduce hallucinations and improve reliability.\\n\\nEnterprise deployment options to keep data secure.Ready to start shipping \\u2028reliable GenAI apps faster?Get started with LangChain, LangSmith, and LangGraph to enhance your LLM app development, from prototype to production.Get a demoSign up for freeProductsLangChainLangSmithLangGraphAgentsEvaluationRetrievalResourcesPython DocsJS/TS DocsGitHubIntegrationsChangelogLangSmith Trust PortalCompanyAboutBlogTwitterLinkedInYouTubeCommunityMarketing AssetsSign up for our newsletter to stay up to dateThank you! Your submission has been received!Oops! Something went wrong while submitting the form.All systems operationalPrivacy PolicyTerms of Service\\n\")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ArxivLoader(\n",
    "    query = 'ChatGTP',\n",
    "    load_max_docs = 2,\n",
    "    load_all_available_mata = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2023-02-01',\n",
       " 'Title': 'Could an Artificial-Intelligence agent pass an introductory physics course?',\n",
       " 'Authors': 'Gerd Kortemeyer',\n",
       " 'Summary': 'Massive pre-trained language models have garnered attention and controversy\\ndue to their ability to generate human-like responses: attention due to their\\nfrequent indistinguishability from human-generated phraseology and narratives,\\nand controversy due to the fact that their convincingly presented arguments and\\nfacts are frequently simply false. Just how human-like are these responses when\\nit comes to dialogues about physics, in particular about the standard content\\nof introductory physics courses? This study explores that question by having\\nChatGTP, the pre-eminent language model in 2023, work through representative\\nassessment content of an actual calculus-based physics course and grading the\\nresponses in the same way human responses would be graded. As it turns out,\\nChatGPT would narrowly pass this course while exhibiting many of the\\npreconceptions and errors of a beginning learner.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2023-09-26',\n",
       " 'Title': 'ChatGPT impacts in programming education: A recent literature overview that debates ChatGPT responses',\n",
       " 'Authors': 'Christos-Nikolaos Anagnostopoulos',\n",
       " 'Summary': 'This paper aims at a brief overview of the main impact of ChatGTP in the\\nscientific field of programming and learning/education in computer science. It\\nlists, covers and documents from the literature the major issues that have been\\nidentified for this topic, such as applications, advantages and limitations,\\nethical issues raised. Answers to the above questions were solicited from\\nChatGPT itself, the responses were collected, and then the recent literature\\nwas surveyed to determine whether or not the responses are supported. The paper\\nends with a short discussion on what is expected to happen in the near future.\\nA future that can be extremely promising if humanity manages to have AI as a\\nproper ally and partner, with distinct roles and specific rules of cooperation\\nand interaction.'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massive pre-trained language models have garnered attention and controversy\n",
      "due to their ability to generate human-like responses: attention due to their\n",
      "frequent indistinguishability from human-generated phraseology and narratives,\n",
      "and controversy due to the fact that their convincingly presented arguments and\n",
      "facts are frequently simply false. Just how human-like are these responses when\n",
      "it comes to dialogues about physics, in particular about the standard content\n",
      "of introductory physics courses? This study explores that question by having\n",
      "ChatGTP, the pre-eminent language model in 2023, work through representative\n",
      "assessment content of an actual calculus-based physics course and grading the\n",
      "responses in the same way human responses would be graded. As it turns out,\n",
      "ChatGPT would narrowly pass this course while exhibiting many of the\n",
      "preconceptions and errors of a beginning learner.\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì„œ ì „ì²´ ìš”ì•½ë³¸ Summaryë¶€ë¶„ ë³´ê¸°\n",
    "docs = loader.get_summaries_as_docs()\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv.org\n",
    "# ìˆ˜í•™ ì»´í“¨í„°ê³¼í•™ ë¬¼ë¦¬ ì „ê¸° ... ë…¼ë¬¸ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
