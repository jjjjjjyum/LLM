{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 🌼 RAG기법의 이해와 적용(2) - 3차시(24.12.02)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CLASS\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"CLASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./appendix-keywords.txt') as f :\n",
    "    file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "\n",
      "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
      "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
      "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
      "\n",
      "Token\n",
      "\n",
      "정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 \n"
     ]
    }
   ],
   "source": [
    "print(file[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-text-splitters) (0.3.21)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (0.28.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (2.23.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-text-splitters) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain-text-splitters tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "# CharacterTextSplitter : 텍스트를 chunk로 분할\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size= 250,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "# 문자 단위로 자름 / 텍스트 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding'\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.create_documents([file])\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = [\n",
    "    {'document': 1},\n",
    "    {'document': 2}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding' metadata={'document': 1}\n"
     ]
    }
   ],
   "source": [
    "documents = text_splitter.create_documents(\n",
    "    [file,file],\n",
    "    metadatas= metadatas\n",
    ")\n",
    "print(documents[0])\n",
    "\n",
    "# 메타데이터 개수와 문서의 개수가 같거나 메타데이터 개수가 더 많아야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='멀티모달 (Multimodal)\n",
      "\n",
      "정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\n",
      "예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\n",
      "연관키워드: 데이터 융합, 인공지능, 딥러닝' metadata={'document': 2}\n"
     ]
    }
   ],
   "source": [
    "print(documents[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-text-splitters tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 358, which is longer than the specified 300\n",
      "Created a chunk of size 315, which is longer than the specified 300\n",
      "Created a chunk of size 305, which is longer than the specified 300\n",
      "Created a chunk of size 366, which is longer than the specified 300\n",
      "Created a chunk of size 330, which is longer than the specified 300\n",
      "Created a chunk of size 351, which is longer than the specified 300\n",
      "Created a chunk of size 378, which is longer than the specified 300\n",
      "Created a chunk of size 361, which is longer than the specified 300\n",
      "Created a chunk of size 350, which is longer than the specified 300\n",
      "Created a chunk of size 362, which is longer than the specified 300\n",
      "Created a chunk of size 335, which is longer than the specified 300\n",
      "Created a chunk of size 353, which is longer than the specified 300\n",
      "Created a chunk of size 358, which is longer than the specified 300\n",
      "Created a chunk of size 336, which is longer than the specified 300\n",
      "Created a chunk of size 324, which is longer than the specified 300\n",
      "Created a chunk of size 337, which is longer than the specified 300\n",
      "Created a chunk of size 307, which is longer than the specified 300\n",
      "Created a chunk of size 361, which is longer than the specified 300\n",
      "Created a chunk of size 354, which is longer than the specified 300\n",
      "Created a chunk of size 378, which is longer than the specified 300\n",
      "Created a chunk of size 381, which is longer than the specified 300\n",
      "Created a chunk of size 365, which is longer than the specified 300\n",
      "Created a chunk of size 377, which is longer than the specified 300\n",
      "Created a chunk of size 329, which is longer than the specified 300\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap=5\n",
    ")\n",
    "texts = text_splitter.split_text(file)\n",
    "# 토큰 단위로 나누어짐 , 의미있는 단위로 나뉠수 있도록\n",
    "# 기본 구분자인 \\n\\n 를 기준으로 분할하는데, \n",
    "# 구분자가 문장 내에서 발견되지 앟아 분할할 수 없는경우 chunk_size보다 큰 chunk가 생성 될 수 있음\n",
    "# 설정한 300보다 큰 청크 사이즈로 나누어졌다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"�\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "# 오로지 토큰으로만 분할되면 될 경우 \n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "texts =text_splitter.split_text(file)\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Downloading torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 4.5/203.1 MB 20.7 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 10.2/203.1 MB 24.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 16.8/203.1 MB 26.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 20.2/203.1 MB 26.0 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 26.5/203.1 MB 24.7 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 32.5/203.1 MB 25.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 38.5/203.1 MB 25.8 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 44.6/203.1 MB 25.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 50.6/203.1 MB 26.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 56.1/203.1 MB 26.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 63.4/203.1 MB 26.8 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 69.2/203.1 MB 26.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 75.5/203.1 MB 26.9 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 79.4/203.1 MB 26.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 85.7/203.1 MB 26.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 90.7/203.1 MB 26.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 96.2/203.1 MB 26.2 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 102.0/203.1 MB 26.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 108.3/203.1 MB 26.5 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 114.3/203.1 MB 26.5 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 119.5/203.1 MB 26.6 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 124.3/203.1 MB 26.2 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 130.3/203.1 MB 26.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 135.8/203.1 MB 26.3 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 141.6/203.1 MB 26.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 148.1/203.1 MB 26.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 152.8/203.1 MB 26.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 158.9/203.1 MB 26.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 165.7/203.1 MB 26.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 171.2/203.1 MB 26.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.7/203.1 MB 26.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 182.5/203.1 MB 26.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.0/203.1 MB 25.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.5/203.1 MB 25.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.0/203.1 MB 26.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.3/203.1 MB 25.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 25.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 25.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.1/203.1 MB 24.8 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.8/11.0 MB 27.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 27.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 25.5 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 7.1/44.8 MB 33.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 12.3/44.8 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.3/44.8 MB 27.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 22.8/44.8 MB 26.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 28.0/44.8 MB 26.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.1/44.8 MB 26.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.6/44.8 MB 26.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.6/44.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 MB 25.9 MB/s eta 0:00:00\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 19.4 MB/s eta 0:00:00\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 23.6 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, networkx, MarkupSafe, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.3 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.2 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.3.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.20.3 torch-2.5.1 transformers-4.46.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\RMARKET\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "# 트렌스토머에 특화된 분활기\n",
    "splitter = SentenceTransformersTokenTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7686\n"
     ]
    }
   ],
   "source": [
    "count_start_and_stop_token = 2\n",
    "# trnasformer 모델에 시작과 끝을 알리는 토큰을 제거\n",
    "\n",
    "text_token_count = splitter.count_tokens(text = file) - count_start_and_stop_token\n",
    "print(text_token_count)\n",
    "# 모델 입력 제한 초과하지 않도록 토큰 개수를 조정하기 위해\n",
    "# eos sos등 문장의 시작과 끝 토큰을 제외한 나머지 토큰 수를 출력\n",
    "# 인지, 참고값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = splitter.split_text(text=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 [UNK] 합니다. [UNK] : \" 사과 \" 라는 단어를 [ 0. 65, - 0. 23, 0. 17 ] 과 [UNK] 벡터로 표현합니다. 연관키워드 : 자연어 처리, 벡터화, 딥러닝 token 정의 : 토큰은 텍스트를 더 작은 [UNK] 분할하는 [UNK] 의미합니다. 이는 일반적으로 단어, 문장, [UNK] 구절일 수 [UNK]. [UNK] : 문장 \" 나는 학교에 간다 \" 를 \" 나는 \", \" 학교에 \", \" 간다 \" 로 분할합니다. 연관키워드 : 토큰화, 자연어 처리, 구문 분석 tokenizer\n"
     ]
    }
   ],
   "source": [
    "print(text_chunks[1])\n",
    "# ## : 문장이 이어진다\n",
    "# [UNK] : 단어 사전에 없는 특수 단어나 특수 기호 등을 대체하는 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\RMARKET\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "hf_tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "# 허깅페이스에서 gpt2의 tokenizer를 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    hf_tokenizer,\n",
    "    chunk_size =300,\n",
    "    chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 358, which is longer than the specified 300\n",
      "Created a chunk of size 315, which is longer than the specified 300\n",
      "Created a chunk of size 305, which is longer than the specified 300\n",
      "Created a chunk of size 366, which is longer than the specified 300\n",
      "Created a chunk of size 330, which is longer than the specified 300\n",
      "Created a chunk of size 351, which is longer than the specified 300\n",
      "Created a chunk of size 378, which is longer than the specified 300\n",
      "Created a chunk of size 361, which is longer than the specified 300\n",
      "Created a chunk of size 350, which is longer than the specified 300\n",
      "Created a chunk of size 362, which is longer than the specified 300\n",
      "Created a chunk of size 335, which is longer than the specified 300\n",
      "Created a chunk of size 353, which is longer than the specified 300\n",
      "Created a chunk of size 358, which is longer than the specified 300\n",
      "Created a chunk of size 336, which is longer than the specified 300\n",
      "Created a chunk of size 324, which is longer than the specified 300\n",
      "Created a chunk of size 337, which is longer than the specified 300\n",
      "Created a chunk of size 307, which is longer than the specified 300\n",
      "Created a chunk of size 361, which is longer than the specified 300\n",
      "Created a chunk of size 354, which is longer than the specified 300\n",
      "Created a chunk of size 378, which is longer than the specified 300\n",
      "Created a chunk of size 381, which is longer than the specified 300\n",
      "Created a chunk of size 365, which is longer than the specified 300\n",
      "Created a chunk of size 377, which is longer than the specified 300\n",
      "Created a chunk of size 329, which is longer than the specified 300\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_text(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n"
     ]
    }
   ],
   "source": [
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '임베딩 테스트를 하기 위한 샘플 문장입니다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.00776276458054781,\n",
       " 0.03680367395281792,\n",
       " 0.019545823335647583,\n",
       " -0.0196656696498394,\n",
       " 0.017203375697135925]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.007761634886264801,\n",
       " 0.03675474599003792,\n",
       " 0.019477618858218193,\n",
       " -0.019760848954319954,\n",
       " 0.017146404832601547]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_result = embeddings.embed_documents([text])\n",
    "doc_result[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1024 = OpenAIEmbeddings(model = 'text-embedding-3-small', dimensions=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_1024.embed_documents([text][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = '오늘 날씨는 맑고 기분이 좋다. 책을 읽으며 시간을 보내고 싶다.'\n",
    "sentence2 = '내일은 친구와 함께 영화 보러 가기로 했다. 기대돼!'\n",
    "sentence3 = '얼어 죽어도 아이스 아메리카노'\n",
    "sentence4 = 'The project is going well'\n",
    "sentence5 = 'we are making good progress.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence1,sentence2,sentence3,sentence4,sentence5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sentence = embeddings_1024.embed_documents(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a,b):\n",
    "    return cosine_similarity([a],[b])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[유사도 0.3714] 오늘 날씨는 맑고 기분이 좋다. 책을 읽으며 시간을 보내고 싶다. <-> 내일은 친구와 함께 영화 보러 가기로 했다. 기대돼!\n",
      "[유사도 0.1451] 오늘 날씨는 맑고 기분이 좋다. 책을 읽으며 시간을 보내고 싶다. <-> 얼어 죽어도 아이스 아메리카노\n",
      "[유사도 0.1510] 오늘 날씨는 맑고 기분이 좋다. 책을 읽으며 시간을 보내고 싶다. <-> The project is going well\n",
      "[유사도 0.1347] 오늘 날씨는 맑고 기분이 좋다. 책을 읽으며 시간을 보내고 싶다. <-> we are making good progress.\n",
      "[유사도 0.1864] 내일은 친구와 함께 영화 보러 가기로 했다. 기대돼! <-> 얼어 죽어도 아이스 아메리카노\n",
      "[유사도 0.1034] 내일은 친구와 함께 영화 보러 가기로 했다. 기대돼! <-> The project is going well\n",
      "[유사도 0.1362] 내일은 친구와 함께 영화 보러 가기로 했다. 기대돼! <-> we are making good progress.\n",
      "[유사도 -0.0059] 얼어 죽어도 아이스 아메리카노 <-> The project is going well\n",
      "[유사도 -0.0030] 얼어 죽어도 아이스 아메리카노 <-> we are making good progress.\n",
      "[유사도 0.6207] The project is going well <-> we are making good progress.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(embedded_sentence):\n",
    "    for j, other_sentence in enumerate(embedded_sentence):\n",
    "        if i < j:\n",
    "            print(f'[유사도 {similarity(sentence , other_sentence):.4f}] {sentences[i]} <-> {sentences[j]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = '오늘 날씨는 맑고 기분이 좋다.'\n",
    "sentence2 = '내일은 친구와 함께 영화 보러 가기로 했다.'\n",
    "sentence3 = '기대돼!'\n",
    "sentence4 = 'AI 윤리 토론을 나눴다.'\n",
    "sentence5 = '저는 그렇게 생각 안해요.'\n",
    "\n",
    "sentences = [sentence1,sentence2,sentence3,sentence4,sentence5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[유사도 0.3714] 오늘 날씨는 맑고 기분이 좋다. <-> 내일은 친구와 함께 영화 보러 가기로 했다.\n",
      "[유사도 0.1451] 오늘 날씨는 맑고 기분이 좋다. <-> 기대돼!\n",
      "[유사도 0.1510] 오늘 날씨는 맑고 기분이 좋다. <-> AI 윤리 토론을 나눴다.\n",
      "[유사도 0.1347] 오늘 날씨는 맑고 기분이 좋다. <-> 저는 그렇게 생각 안해요.\n",
      "[유사도 0.1864] 내일은 친구와 함께 영화 보러 가기로 했다. <-> 기대돼!\n",
      "[유사도 0.1034] 내일은 친구와 함께 영화 보러 가기로 했다. <-> AI 윤리 토론을 나눴다.\n",
      "[유사도 0.1362] 내일은 친구와 함께 영화 보러 가기로 했다. <-> 저는 그렇게 생각 안해요.\n",
      "[유사도 -0.0059] 기대돼! <-> AI 윤리 토론을 나눴다.\n",
      "[유사도 -0.0030] 기대돼! <-> 저는 그렇게 생각 안해요.\n",
      "[유사도 0.6207] AI 윤리 토론을 나눴다. <-> 저는 그렇게 생각 안해요.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(embedded_sentence):\n",
    "    for j, other_sentence in enumerate(embedded_sentence):\n",
    "        if i < j:\n",
    "            print(f'[유사도 {similarity(sentence , other_sentence):.4f}] {sentences[i]} <-> {sentences[j]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 100, chunk_overlap = 0)\n",
    "\n",
    "loader1 = TextLoader('./nlp-keywords.txt')\n",
    "loader2 = TextLoader('./finance-keywords.txt')\n",
    "# TextLoader로 불러오면 Document 리스트 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x2cfa2b6bf90>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer\\n\\n정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV\\n\\n정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace\\n\\n정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec\\n\\n정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source\\n\\n정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)\\n\\n정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame\\n\\n정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 \\'주의\\'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\\n\\nGPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search\\n\\n정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)\\n\\n정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝\\n')]\n"
     ]
    }
   ],
   "source": [
    "documents = loader1.load()\n",
    "print(documents)\n",
    "# list Documents 형태로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_doc1 = loader1.load_and_split(text_splitter)\n",
    "split_doc2 = loader2.load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Embedding'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Token'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Tokenizer'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 토큰화, 자연어 처리, 구문 분석'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='VectorStore'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='SQL'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='수행할 수 있습니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='CSV'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='JSON'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Transformer'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='HuggingFace'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='돕습니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 자연어 처리, 딥러닝, 라이브러리'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Digital Transformation'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Crawling'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Word2Vec'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='LLM (Large Language Model)'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='FAISS (Facebook AI Similarity Search)'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Open Source'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Structured Data'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Parser'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='TF-IDF (Term Frequency-Inverse Document Frequency)'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Deep Learning'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Schema'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='DataFrame'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 데이터 분석, 판다스, 데이터 처리'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Attention 메커니즘'), Document(metadata={'source': './nlp-keywords.txt'}, page_content=\"정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서\"), Document(metadata={'source': './nlp-keywords.txt'}, page_content='사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='판다스 (Pandas)'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='있습니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='InstructGPT'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='설계되었습니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 인공지능, 자연어 이해, 명령 기반 처리'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Keyword Search'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='Page Rank'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='데이터 마이닝'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='멀티모달 (Multimodal)'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='정확한 정보를 추출하거나 예측하는 데 사용됩니다.'), Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝')]\n"
     ]
    }
   ],
   "source": [
    "print(split_doc1)\n",
    "# 문서가 여러개의 청크로 분활되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 60)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_doc1), len(split_doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\rmarket\\anaconda3\\envs\\langchain\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.9.0.post1-cp311-cp311-win_amd64.whl (13.8 MB)\n",
      "   ---------------------------------------- 0.0/13.8 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.4/13.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.0/13.8 MB 23.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.8/13.8 MB 24.2 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install faiss-cpu\n",
    "# 페이스북에서 만든 벡터DB 라이브러리\n",
    "# 빠르고 확장성도 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n"
     ]
    }
   ],
   "source": [
    "dimension_size = len(embeddings.embed_query('임베딩 차원 크기'))\n",
    "print(dimension_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    # 임베딩 함수\n",
    "    index = faiss.IndexFlatL2(dimension_size),\n",
    "    # 사용할 FAISS 인덱스\n",
    "    docstore = InMemoryDocstore(),\n",
    "    # 사용할 문서 저장소\n",
    "    index_to_docstore_id = {}\n",
    "    # 인덱스에서 문서 저장소  ID로 매핑\n",
    ")\n",
    "\n",
    "# 0.3 , 0.4 , 0.7 -> 유클리디안 거리 계산 결과로 INDEX가 1을 부여받았다고 가정\n",
    "# index_to_docstore_id = {1:[0.3,0.4,0.7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(documents = split_doc1, embedding = OpenAIEmbeddings())\n",
    "# 자동으로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Embedding'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Token'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Tokenizer'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 토큰화, 자연어 처리, 구문 분석'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='VectorStore'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='SQL'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='수행할 수 있습니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='CSV'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='JSON'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Transformer'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='HuggingFace'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='돕습니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 자연어 처리, 딥러닝, 라이브러리'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Digital Transformation'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Crawling'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Word2Vec'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='LLM (Large Language Model)'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='FAISS (Facebook AI Similarity Search)'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Open Source'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Structured Data'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Parser'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='TF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Deep Learning'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Schema'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='DataFrame'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 데이터 분석, 판다스, 데이터 처리'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Attention 메커니즘'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content=\"정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서\"),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='판다스 (Pandas)'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='있습니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='InstructGPT'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='설계되었습니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 인공지능, 자연어 이해, 명령 기반 처리'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Keyword Search'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Page Rank'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='데이터 마이닝'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='멀티모달 (Multimodal)'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정확한 정보를 추출하거나 예측하는 데 사용됩니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '30f12a86-0926-4fe0-955e-26d1a443bacc',\n",
       " 1: '5f8c14b7-2249-4ce0-a208-7c3f4bbadcb9',\n",
       " 2: '4bacaf7e-dfac-45c5-8621-ad2f915d6375',\n",
       " 3: 'b3baddc4-34cb-4f47-ae1b-2f69ee3c65c2',\n",
       " 4: '930fec7c-9c68-48fa-ac3d-fdaaa8a71b17',\n",
       " 5: '74b21bf4-357a-432b-a1cd-0778e3a0bef8',\n",
       " 6: '3db0c5da-f195-46ce-9b69-5c6070b8db01',\n",
       " 7: '46436281-4812-4ae7-a9a7-17acfee33b54',\n",
       " 8: 'f1e891c0-b1c9-46d6-b4e7-424e89e3d475',\n",
       " 9: 'a321a763-01d2-4861-96a9-82da1f76d8dd',\n",
       " 10: 'f93ba595-6a59-4fba-935b-88463cc37dea',\n",
       " 11: '9a69641b-f542-4e10-be9c-8dbbbc8bc843',\n",
       " 12: '06509079-68c8-4c12-9e58-71336718cf31',\n",
       " 13: '53263ce5-5686-4a1b-a7d7-1ebbe3fc6ee7',\n",
       " 14: 'b879ee1e-617a-44cc-ac2b-a637e2f23273',\n",
       " 15: 'fb6fda78-b54f-4b38-a0e2-99f4f8d93e1a',\n",
       " 16: '2e1bf514-1dea-45fd-9e59-58f387cae09a',\n",
       " 17: 'cce76cc8-47eb-4a70-81a0-b5a06329aa6b',\n",
       " 18: '47230d53-502f-4e87-871c-88849f65db54',\n",
       " 19: '526c1317-e937-4b77-aa37-3ea8070990f6',\n",
       " 20: 'c6a0610e-e679-4c59-8304-16d953578723',\n",
       " 21: '7c3e0f78-128e-422b-b147-3d956f760402',\n",
       " 22: '98c6d7bf-39e5-4933-b052-2d18a4874f86',\n",
       " 23: '26bfc631-24f9-413f-bbd6-f0ea4be38397',\n",
       " 24: '3eb2bd16-fb4c-4c35-99eb-f016c4e0add1',\n",
       " 25: '409cdec5-652d-4e15-9e2d-df197f9f500d',\n",
       " 26: '5851c9b3-9dfd-4c4b-b6e6-35bc47f8762b',\n",
       " 27: '0e61fa27-4bb8-42fe-ae6f-003c707fe5f3',\n",
       " 28: '0354776b-4039-495a-a84a-9febff9ec992',\n",
       " 29: '6042bc07-0f31-4a2a-836d-0d9b5267b54d',\n",
       " 30: '271204df-ce76-4d20-8511-0cc0794141f8',\n",
       " 31: '8b85ca64-b5b7-431c-87c1-28a7a3d956ce',\n",
       " 32: 'a194547a-87fd-485b-ad4e-8b53e5e8224c',\n",
       " 33: 'e4789242-4e34-47ea-8df6-60e96a81b3ed',\n",
       " 34: '5a51a475-f005-4e45-afea-8c1e9c352405',\n",
       " 35: '98c963c9-43a5-4bed-984c-78fc761c0431',\n",
       " 36: '15272b50-6686-4c34-921f-b80189b3c7ac',\n",
       " 37: '4193d2a6-e19e-480e-afb5-b6ea71babfa4',\n",
       " 38: '010a345c-c890-4032-9e2d-321d610a0c67',\n",
       " 39: 'cae1d444-9d6b-4b3e-8a83-c6bc583c67df',\n",
       " 40: '8bd97f16-bb68-43e0-ae95-e104e0cbfe72',\n",
       " 41: '99c0cd26-1dff-488e-bb8a-4276f3b83559',\n",
       " 42: 'a9c93885-d9ed-496f-bbb8-b4fdaff6d402',\n",
       " 43: 'ea3347c4-f871-4a94-acc5-693ae9d61ee7',\n",
       " 44: '3de48a29-762e-4d0c-b7db-2496cb6f6156',\n",
       " 45: '69c2a32f-23b9-4f98-9417-f872eebc6712',\n",
       " 46: 'ef39b89c-f439-40f0-8298-8dbf0907ea8c',\n",
       " 47: 'b9f5e175-8133-4898-885d-629976b1c07a',\n",
       " 48: 'c778ebdc-8ca6-464d-afac-8689147c2f59',\n",
       " 49: '189637d7-f901-4890-8bbb-3f0d3473ca63',\n",
       " 50: '25420f0e-2363-41ea-bb04-203bebccc472',\n",
       " 51: '96ef1900-88e4-4e3d-9b2b-2dae83ae58ba',\n",
       " 52: 'd8562702-64cb-4281-a333-1f9bc1944af6',\n",
       " 53: '8df64439-efa8-4f14-b7cf-e7e29f39515a',\n",
       " 54: 'e6965448-9792-4e09-953a-162a7450811a',\n",
       " 55: '19d9399f-b6f8-475d-88c9-35e3265f5195',\n",
       " 56: '88a9b3c3-f683-4a63-b04f-dfeca6c62057',\n",
       " 57: '569cab06-a98e-4106-a34c-675b11b97229',\n",
       " 58: '5482f8f9-b95c-476b-81e6-5b603c9832b2',\n",
       " 59: '4934eeb9-3ec2-4a62-8ab5-cb965b789265',\n",
       " 60: '2807fe19-dfcf-45ba-a52a-b9341a92ee60',\n",
       " 61: '19705242-5e35-4022-8a72-0723a09dbbc8',\n",
       " 62: '26eff41b-65fd-4a93-9487-67f0bbcb235c',\n",
       " 63: '7879f2f3-2790-41a5-b2ca-a7bb15094b1c',\n",
       " 64: '43366f3e-5073-4977-bab7-4b94de4266bb',\n",
       " 65: 'c0fa13fe-0a8d-44ac-bb43-b2b18fc497ce',\n",
       " 66: '0291909c-9c5c-4f43-acac-94043e8abde8',\n",
       " 67: 'f86a805d-5a6f-4e05-833f-34616ffd14b8',\n",
       " 68: 'c70613d9-1143-42c0-aa02-d68303c3322f',\n",
       " 69: '5b992f14-e7e9-4093-9169-e93ca3a08b6e',\n",
       " 70: '9d96bf1e-c5b0-4e5e-a88c-63ab99ffca38',\n",
       " 71: '845a146d-a113-4174-a1c1-f9e28023ddea',\n",
       " 72: '0b52dffe-1c76-4ae3-9e09-555011bf3edc',\n",
       " 73: '60dfc849-c0be-481f-a67a-e873dcc0b2c9',\n",
       " 74: 'a9a6aa44-4920-4b99-9973-07ff4d8cbadd',\n",
       " 75: '9b74d8f9-b68c-489f-8605-f54a06555559',\n",
       " 76: 'bf293bc4-ca64-48e5-a9ac-307616e5e1a1',\n",
       " 77: 'f3cb401c-66de-4891-ab17-447fe4eba8f6',\n",
       " 78: 'c5e00ed6-3bc1-419f-95db-b441fe0aa0f5',\n",
       " 79: 'c02c30da-2cf8-413a-84fa-77980c7c0a8f',\n",
       " 80: '22ca602f-54ac-4e22-8fd5-254c94d4f5ae',\n",
       " 81: '175a435c-7761-4d1e-a85f-efd767932330',\n",
       " 82: '29038ade-a124-4464-899f-e35ae6dfb989',\n",
       " 83: '66a32654-d05e-48b0-bb8f-8d4fda72e126',\n",
       " 84: '0bf47069-1ddc-436f-bf18-42dc0c102523',\n",
       " 85: '492d424a-0ddf-4055-a7e9-caa52d7b8bfb',\n",
       " 86: '18e1b971-0b22-4031-ae43-fd2b7f620c91',\n",
       " 87: '62093228-a180-4efa-afce-a8b02aefa32d',\n",
       " 88: 'bdb65684-4da4-4dc0-8ebb-2a22df63d64c',\n",
       " 89: '4d9d25cf-5edc-450f-92ad-38810ae8759b',\n",
       " 90: 'bc2cf47d-9ab5-4416-96a7-04466980696e',\n",
       " 91: '3c9b96ba-f259-4bb9-b2e5-eb28c7264326',\n",
       " 92: '0836cf47-1c44-46e6-9775-6e67473385eb',\n",
       " 93: '95f4048c-8431-46c9-b3c4-76dc015735f2',\n",
       " 94: 'bd855735-bab2-4457-a94b-54703e154579',\n",
       " 95: '184f858d-94c6-44d7-a17f-8dab261fa072',\n",
       " 96: 'ad235481-c459-466d-8e00-dd22a5d0e16b',\n",
       " 97: 'e5310b95-af53-48b4-a460-2e9db00138cd',\n",
       " 98: '74053538-ed89-4874-84f8-c9953bd19796',\n",
       " 99: '5cff24c0-6c33-4733-a6de-209734310804',\n",
       " 100: '5e258043-8bb5-435b-aa5d-9c91069c27c4'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index_to_docstore_id\n",
    "# 문서 저장소 ID와 FAISS 벡터 ID를 매핑하는 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'30f12a86-0926-4fe0-955e-26d1a443bacc': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search'),\n",
       " '5f8c14b7-2249-4ce0-a208-7c3f4bbadcb9': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.'),\n",
       " '4bacaf7e-dfac-45c5-8621-ad2f915d6375': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝'),\n",
       " 'b3baddc4-34cb-4f47-ae1b-2f69ee3c65c2': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Embedding'),\n",
       " '930fec7c-9c68-48fa-ac3d-fdaaa8a71b17': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.'),\n",
       " '74b21bf4-357a-432b-a1cd-0778e3a0bef8': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝'),\n",
       " '3db0c5da-f195-46ce-9b69-5c6070b8db01': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Token'),\n",
       " '46436281-4812-4ae7-a9a7-17acfee33b54': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.'),\n",
       " 'f1e891c0-b1c9-46d6-b4e7-424e89e3d475': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석'),\n",
       " 'a321a763-01d2-4861-96a9-82da1f76d8dd': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Tokenizer'),\n",
       " 'f93ba595-6a59-4fba-935b-88463cc37dea': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.'),\n",
       " '9a69641b-f542-4e10-be9c-8dbbbc8bc843': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.'),\n",
       " '06509079-68c8-4c12-9e58-71336718cf31': Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 토큰화, 자연어 처리, 구문 분석'),\n",
       " '53263ce5-5686-4a1b-a7d7-1ebbe3fc6ee7': Document(metadata={'source': './nlp-keywords.txt'}, page_content='VectorStore'),\n",
       " 'b879ee1e-617a-44cc-ac2b-a637e2f23273': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.'),\n",
       " 'fb6fda78-b54f-4b38-a0e2-99f4f8d93e1a': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화'),\n",
       " '2e1bf514-1dea-45fd-9e59-58f387cae09a': Document(metadata={'source': './nlp-keywords.txt'}, page_content='SQL'),\n",
       " 'cce76cc8-47eb-4a70-81a0-b5a06329aa6b': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을'),\n",
       " '47230d53-502f-4e87-871c-88849f65db54': Document(metadata={'source': './nlp-keywords.txt'}, page_content='수행할 수 있습니다.'),\n",
       " '526c1317-e937-4b77-aa37-3ea8070990f6': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리'),\n",
       " 'c6a0610e-e679-4c59-8304-16d953578723': Document(metadata={'source': './nlp-keywords.txt'}, page_content='CSV'),\n",
       " '7c3e0f78-128e-422b-b147-3d956f760402': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때'),\n",
       " '98c6d7bf-39e5-4933-b052-2d18a4874f86': Document(metadata={'source': './nlp-keywords.txt'}, page_content='사용됩니다.'),\n",
       " '26bfc631-24f9-413f-bbd6-f0ea4be38397': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환'),\n",
       " '3eb2bd16-fb4c-4c35-99eb-f016c4e0add1': Document(metadata={'source': './nlp-keywords.txt'}, page_content='JSON'),\n",
       " '409cdec5-652d-4e15-9e2d-df197f9f500d': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.'),\n",
       " '5851c9b3-9dfd-4c4b-b6e6-35bc47f8762b': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API'),\n",
       " '0e61fa27-4bb8-42fe-ae6f-003c707fe5f3': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Transformer'),\n",
       " '0354776b-4039-495a-a84a-9febff9ec992': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.'),\n",
       " '6042bc07-0f31-4a2a-836d-0d9b5267b54d': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention'),\n",
       " '271204df-ce76-4d20-8511-0cc0794141f8': Document(metadata={'source': './nlp-keywords.txt'}, page_content='HuggingFace'),\n",
       " '8b85ca64-b5b7-431c-87c1-28a7a3d956ce': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록'),\n",
       " 'a194547a-87fd-485b-ad4e-8b53e5e8224c': Document(metadata={'source': './nlp-keywords.txt'}, page_content='돕습니다.'),\n",
       " 'e4789242-4e34-47ea-8df6-60e96a81b3ed': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.'),\n",
       " '5a51a475-f005-4e45-afea-8c1e9c352405': Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 자연어 처리, 딥러닝, 라이브러리'),\n",
       " '98c963c9-43a5-4bed-984c-78fc761c0431': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Digital Transformation'),\n",
       " '15272b50-6686-4c34-921f-b80189b3c7ac': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.'),\n",
       " '4193d2a6-e19e-480e-afb5-b6ea71babfa4': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델'),\n",
       " '010a345c-c890-4032-9e2d-321d610a0c67': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Crawling'),\n",
       " 'cae1d444-9d6b-4b3e-8a83-c6bc583c67df': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.'),\n",
       " '8bd97f16-bb68-43e0-ae95-e104e0cbfe72': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진'),\n",
       " '99c0cd26-1dff-488e-bb8a-4276f3b83559': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Word2Vec'),\n",
       " 'a9c93885-d9ed-496f-bbb8-b4fdaff6d402': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.'),\n",
       " 'ea3347c4-f871-4a94-acc5-693ae9d61ee7': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성'),\n",
       " '3de48a29-762e-4d0c-b7db-2496cb6f6156': Document(metadata={'source': './nlp-keywords.txt'}, page_content='LLM (Large Language Model)'),\n",
       " '69c2a32f-23b9-4f98-9417-f872eebc6712': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.'),\n",
       " 'ef39b89c-f439-40f0-8298-8dbf0907ea8c': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성'),\n",
       " 'b9f5e175-8133-4898-885d-629976b1c07a': Document(metadata={'source': './nlp-keywords.txt'}, page_content='FAISS (Facebook AI Similarity Search)'),\n",
       " 'c778ebdc-8ca6-464d-afac-8689147c2f59': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.'),\n",
       " '189637d7-f901-4890-8bbb-3f0d3473ca63': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화'),\n",
       " '25420f0e-2363-41ea-bb04-203bebccc472': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Open Source'),\n",
       " '96ef1900-88e4-4e3d-9b2b-2dae83ae58ba': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.'),\n",
       " 'd8562702-64cb-4281-a333-1f9bc1944af6': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업'),\n",
       " '8df64439-efa8-4f14-b7cf-e7e29f39515a': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Structured Data'),\n",
       " 'e6965448-9792-4e09-953a-162a7450811a': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.'),\n",
       " '19d9399f-b6f8-475d-88c9-35e3265f5195': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링'),\n",
       " '88a9b3c3-f683-4a63-b04f-dfeca6c62057': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Parser'),\n",
       " '569cab06-a98e-4106-a34c-675b11b97229': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.'),\n",
       " '5482f8f9-b95c-476b-81e6-5b603c9832b2': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리'),\n",
       " '4934eeb9-3ec2-4a62-8ab5-cb965b789265': Document(metadata={'source': './nlp-keywords.txt'}, page_content='TF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
       " '2807fe19-dfcf-45ba-a52a-b9341a92ee60': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.'),\n",
       " '19705242-5e35-4022-8a72-0723a09dbbc8': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝'),\n",
       " '26eff41b-65fd-4a93-9487-67f0bbcb235c': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Deep Learning'),\n",
       " '7879f2f3-2790-41a5-b2ca-a7bb15094b1c': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.'),\n",
       " '43366f3e-5073-4977-bab7-4b94de4266bb': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석'),\n",
       " 'c0fa13fe-0a8d-44ac-bb43-b2b18fc497ce': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Schema'),\n",
       " '0291909c-9c5c-4f43-acac-94043e8abde8': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.'),\n",
       " 'f86a805d-5a6f-4e05-833f-34616ffd14b8': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리'),\n",
       " 'c70613d9-1143-42c0-aa02-d68303c3322f': Document(metadata={'source': './nlp-keywords.txt'}, page_content='DataFrame'),\n",
       " '5b992f14-e7e9-4093-9169-e93ca3a08b6e': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.'),\n",
       " '9d96bf1e-c5b0-4e5e-a88c-63ab99ffca38': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.'),\n",
       " '845a146d-a113-4174-a1c1-f9e28023ddea': Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 데이터 분석, 판다스, 데이터 처리'),\n",
       " '0b52dffe-1c76-4ae3-9e09-555011bf3edc': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Attention 메커니즘'),\n",
       " '60dfc849-c0be-481f-a67a-e873dcc0b2c9': Document(metadata={'source': './nlp-keywords.txt'}, page_content=\"정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서\"),\n",
       " 'a9a6aa44-4920-4b99-9973-07ff4d8cbadd': Document(metadata={'source': './nlp-keywords.txt'}, page_content='사용됩니다.'),\n",
       " '9b74d8f9-b68c-489f-8605-f54a06555559': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링'),\n",
       " 'bf293bc4-ca64-48e5-a9ac-307616e5e1a1': Document(metadata={'source': './nlp-keywords.txt'}, page_content='판다스 (Pandas)'),\n",
       " 'f3cb401c-66de-4891-ab17-447fe4eba8f6': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.'),\n",
       " 'c5e00ed6-3bc1-419f-95db-b441fe0aa0f5': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리'),\n",
       " 'c02c30da-2cf8-413a-84fa-77980c7c0a8f': Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)'),\n",
       " '22ca602f-54ac-4e22-8fd5-254c94d4f5ae': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수'),\n",
       " '175a435c-7761-4d1e-a85f-efd767932330': Document(metadata={'source': './nlp-keywords.txt'}, page_content='있습니다.'),\n",
       " '29038ade-a124-4464-899f-e35ae6dfb989': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝'),\n",
       " '66a32654-d05e-48b0-bb8f-8d4fda72e126': Document(metadata={'source': './nlp-keywords.txt'}, page_content='InstructGPT'),\n",
       " '0bf47069-1ddc-436f-bf18-42dc0c102523': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록'),\n",
       " '492d424a-0ddf-4055-a7e9-caa52d7b8bfb': Document(metadata={'source': './nlp-keywords.txt'}, page_content='설계되었습니다.'),\n",
       " '18e1b971-0b22-4031-ae43-fd2b7f620c91': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.'),\n",
       " '62093228-a180-4efa-afce-a8b02aefa32d': Document(metadata={'source': './nlp-keywords.txt'}, page_content='연관키워드: 인공지능, 자연어 이해, 명령 기반 처리'),\n",
       " 'bdb65684-4da4-4dc0-8ebb-2a22df63d64c': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Keyword Search'),\n",
       " '4d9d25cf-5edc-450f-92ad-38810ae8759b': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.'),\n",
       " 'bc2cf47d-9ab5-4416-96a7-04466980696e': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색'),\n",
       " '3c9b96ba-f259-4bb9-b2e5-eb28c7264326': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Page Rank'),\n",
       " '0836cf47-1c44-46e6-9775-6e67473385eb': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.'),\n",
       " '95f4048c-8431-46c9-b3c4-76dc015735f2': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석'),\n",
       " 'bd855735-bab2-4457-a94b-54703e154579': Document(metadata={'source': './nlp-keywords.txt'}, page_content='데이터 마이닝'),\n",
       " '184f858d-94c6-44d7-a17f-8dab261fa072': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.'),\n",
       " 'ad235481-c459-466d-8e00-dd22a5d0e16b': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석'),\n",
       " 'e5310b95-af53-48b4-a460-2e9db00138cd': Document(metadata={'source': './nlp-keywords.txt'}, page_content='멀티모달 (Multimodal)'),\n",
       " '74053538-ed89-4874-84f8-c9953bd19796': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고'),\n",
       " '5cff24c0-6c33-4733-a6de-209734310804': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정확한 정보를 추출하거나 예측하는 데 사용됩니다.'),\n",
       " '5e258043-8bb5-435b-aa5d-9c91069c27c4': Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝')}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.docstore._dict\n",
    "# 문서 저장소의 모두 문서를 한번에 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열로 db를 생성\n",
    "db2 = FAISS.from_texts(\n",
    "    ['안녕하세요. 오늘은 월요일 입니다','다들 월요팅 입니다.'],\n",
    "    embedding = OpenAIEmbeddings(),\n",
    "    metadatas = [{'source':'텍스트 문서1'},{'source':'텍스트 문서2'}],\n",
    "    ids = ['doc1','doc2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': Document(metadata={'source': '텍스트 문서1'}, page_content='안녕하세요. 오늘은 월요일 입니다'),\n",
       " 'doc2': Document(metadata={'source': '텍스트 문서2'}, page_content='다들 월요팅 입니다.')}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2.docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='TF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('TF IDF 가 뭐야?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='SQL')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('SQL에 대해 알려줘', k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('TF IDF에 대해 알려줘', filter={'source' : './nlp-keywords.txt'}, k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('TF IDF에 대해 알려줘', filter={'source' : './finance-keywords.txt'}, k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_doc1']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 추가\n",
    "db.add_documents(\n",
    "    [\n",
    "        Document(\n",
    "            page_content= '좋습니다. 이번엔 새로운 document를 추가해볼게여',\n",
    "            metadata = {'source':'mydata.txt'} \n",
    "        )\n",
    "    ],\n",
    "    ids = ['new_doc1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'mydata.txt'}, page_content='좋습니다. 이번엔 새로운 document를 추가해볼게여')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search('좋습니다', k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_doc2', 'new_doc3']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_texts(\n",
    "    ['이번엔 텍스트 데이터를 추가합니다','추가한 2번째 텍스트 데이터 입니다.'],\n",
    "    metadatas=[{'source':'mydata.txt'},{'source':'mydata.txt'}],\n",
    "    ids = ['new_doc2','new_doc3']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '30f12a86-0926-4fe0-955e-26d1a443bacc',\n",
       " 1: '5f8c14b7-2249-4ce0-a208-7c3f4bbadcb9',\n",
       " 2: '4bacaf7e-dfac-45c5-8621-ad2f915d6375',\n",
       " 3: 'b3baddc4-34cb-4f47-ae1b-2f69ee3c65c2',\n",
       " 4: '930fec7c-9c68-48fa-ac3d-fdaaa8a71b17',\n",
       " 5: '74b21bf4-357a-432b-a1cd-0778e3a0bef8',\n",
       " 6: '3db0c5da-f195-46ce-9b69-5c6070b8db01',\n",
       " 7: '46436281-4812-4ae7-a9a7-17acfee33b54',\n",
       " 8: 'f1e891c0-b1c9-46d6-b4e7-424e89e3d475',\n",
       " 9: 'a321a763-01d2-4861-96a9-82da1f76d8dd',\n",
       " 10: 'f93ba595-6a59-4fba-935b-88463cc37dea',\n",
       " 11: '9a69641b-f542-4e10-be9c-8dbbbc8bc843',\n",
       " 12: '06509079-68c8-4c12-9e58-71336718cf31',\n",
       " 13: '53263ce5-5686-4a1b-a7d7-1ebbe3fc6ee7',\n",
       " 14: 'b879ee1e-617a-44cc-ac2b-a637e2f23273',\n",
       " 15: 'fb6fda78-b54f-4b38-a0e2-99f4f8d93e1a',\n",
       " 16: '2e1bf514-1dea-45fd-9e59-58f387cae09a',\n",
       " 17: 'cce76cc8-47eb-4a70-81a0-b5a06329aa6b',\n",
       " 18: '47230d53-502f-4e87-871c-88849f65db54',\n",
       " 19: '526c1317-e937-4b77-aa37-3ea8070990f6',\n",
       " 20: 'c6a0610e-e679-4c59-8304-16d953578723',\n",
       " 21: '7c3e0f78-128e-422b-b147-3d956f760402',\n",
       " 22: '98c6d7bf-39e5-4933-b052-2d18a4874f86',\n",
       " 23: '26bfc631-24f9-413f-bbd6-f0ea4be38397',\n",
       " 24: '3eb2bd16-fb4c-4c35-99eb-f016c4e0add1',\n",
       " 25: '409cdec5-652d-4e15-9e2d-df197f9f500d',\n",
       " 26: '5851c9b3-9dfd-4c4b-b6e6-35bc47f8762b',\n",
       " 27: '0e61fa27-4bb8-42fe-ae6f-003c707fe5f3',\n",
       " 28: '0354776b-4039-495a-a84a-9febff9ec992',\n",
       " 29: '6042bc07-0f31-4a2a-836d-0d9b5267b54d',\n",
       " 30: '271204df-ce76-4d20-8511-0cc0794141f8',\n",
       " 31: '8b85ca64-b5b7-431c-87c1-28a7a3d956ce',\n",
       " 32: 'a194547a-87fd-485b-ad4e-8b53e5e8224c',\n",
       " 33: 'e4789242-4e34-47ea-8df6-60e96a81b3ed',\n",
       " 34: '5a51a475-f005-4e45-afea-8c1e9c352405',\n",
       " 35: '98c963c9-43a5-4bed-984c-78fc761c0431',\n",
       " 36: '15272b50-6686-4c34-921f-b80189b3c7ac',\n",
       " 37: '4193d2a6-e19e-480e-afb5-b6ea71babfa4',\n",
       " 38: '010a345c-c890-4032-9e2d-321d610a0c67',\n",
       " 39: 'cae1d444-9d6b-4b3e-8a83-c6bc583c67df',\n",
       " 40: '8bd97f16-bb68-43e0-ae95-e104e0cbfe72',\n",
       " 41: '99c0cd26-1dff-488e-bb8a-4276f3b83559',\n",
       " 42: 'a9c93885-d9ed-496f-bbb8-b4fdaff6d402',\n",
       " 43: 'ea3347c4-f871-4a94-acc5-693ae9d61ee7',\n",
       " 44: '3de48a29-762e-4d0c-b7db-2496cb6f6156',\n",
       " 45: '69c2a32f-23b9-4f98-9417-f872eebc6712',\n",
       " 46: 'ef39b89c-f439-40f0-8298-8dbf0907ea8c',\n",
       " 47: 'b9f5e175-8133-4898-885d-629976b1c07a',\n",
       " 48: 'c778ebdc-8ca6-464d-afac-8689147c2f59',\n",
       " 49: '189637d7-f901-4890-8bbb-3f0d3473ca63',\n",
       " 50: '25420f0e-2363-41ea-bb04-203bebccc472',\n",
       " 51: '96ef1900-88e4-4e3d-9b2b-2dae83ae58ba',\n",
       " 52: 'd8562702-64cb-4281-a333-1f9bc1944af6',\n",
       " 53: '8df64439-efa8-4f14-b7cf-e7e29f39515a',\n",
       " 54: 'e6965448-9792-4e09-953a-162a7450811a',\n",
       " 55: '19d9399f-b6f8-475d-88c9-35e3265f5195',\n",
       " 56: '88a9b3c3-f683-4a63-b04f-dfeca6c62057',\n",
       " 57: '569cab06-a98e-4106-a34c-675b11b97229',\n",
       " 58: '5482f8f9-b95c-476b-81e6-5b603c9832b2',\n",
       " 59: '4934eeb9-3ec2-4a62-8ab5-cb965b789265',\n",
       " 60: '2807fe19-dfcf-45ba-a52a-b9341a92ee60',\n",
       " 61: '19705242-5e35-4022-8a72-0723a09dbbc8',\n",
       " 62: '26eff41b-65fd-4a93-9487-67f0bbcb235c',\n",
       " 63: '7879f2f3-2790-41a5-b2ca-a7bb15094b1c',\n",
       " 64: '43366f3e-5073-4977-bab7-4b94de4266bb',\n",
       " 65: 'c0fa13fe-0a8d-44ac-bb43-b2b18fc497ce',\n",
       " 66: '0291909c-9c5c-4f43-acac-94043e8abde8',\n",
       " 67: 'f86a805d-5a6f-4e05-833f-34616ffd14b8',\n",
       " 68: 'c70613d9-1143-42c0-aa02-d68303c3322f',\n",
       " 69: '5b992f14-e7e9-4093-9169-e93ca3a08b6e',\n",
       " 70: '9d96bf1e-c5b0-4e5e-a88c-63ab99ffca38',\n",
       " 71: '845a146d-a113-4174-a1c1-f9e28023ddea',\n",
       " 72: '0b52dffe-1c76-4ae3-9e09-555011bf3edc',\n",
       " 73: '60dfc849-c0be-481f-a67a-e873dcc0b2c9',\n",
       " 74: 'a9a6aa44-4920-4b99-9973-07ff4d8cbadd',\n",
       " 75: '9b74d8f9-b68c-489f-8605-f54a06555559',\n",
       " 76: 'bf293bc4-ca64-48e5-a9ac-307616e5e1a1',\n",
       " 77: 'f3cb401c-66de-4891-ab17-447fe4eba8f6',\n",
       " 78: 'c5e00ed6-3bc1-419f-95db-b441fe0aa0f5',\n",
       " 79: 'c02c30da-2cf8-413a-84fa-77980c7c0a8f',\n",
       " 80: '22ca602f-54ac-4e22-8fd5-254c94d4f5ae',\n",
       " 81: '175a435c-7761-4d1e-a85f-efd767932330',\n",
       " 82: '29038ade-a124-4464-899f-e35ae6dfb989',\n",
       " 83: '66a32654-d05e-48b0-bb8f-8d4fda72e126',\n",
       " 84: '0bf47069-1ddc-436f-bf18-42dc0c102523',\n",
       " 85: '492d424a-0ddf-4055-a7e9-caa52d7b8bfb',\n",
       " 86: '18e1b971-0b22-4031-ae43-fd2b7f620c91',\n",
       " 87: '62093228-a180-4efa-afce-a8b02aefa32d',\n",
       " 88: 'bdb65684-4da4-4dc0-8ebb-2a22df63d64c',\n",
       " 89: '4d9d25cf-5edc-450f-92ad-38810ae8759b',\n",
       " 90: 'bc2cf47d-9ab5-4416-96a7-04466980696e',\n",
       " 91: '3c9b96ba-f259-4bb9-b2e5-eb28c7264326',\n",
       " 92: '0836cf47-1c44-46e6-9775-6e67473385eb',\n",
       " 93: '95f4048c-8431-46c9-b3c4-76dc015735f2',\n",
       " 94: 'bd855735-bab2-4457-a94b-54703e154579',\n",
       " 95: '184f858d-94c6-44d7-a17f-8dab261fa072',\n",
       " 96: 'ad235481-c459-466d-8e00-dd22a5d0e16b',\n",
       " 97: 'e5310b95-af53-48b4-a460-2e9db00138cd',\n",
       " 98: '74053538-ed89-4874-84f8-c9953bd19796',\n",
       " 99: '5cff24c0-6c33-4733-a6de-209734310804',\n",
       " 100: '5e258043-8bb5-435b-aa5d-9c91069c27c4',\n",
       " 101: 'new_doc1',\n",
       " 102: 'new_doc2',\n",
       " 103: 'new_doc3'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_ids = db.add_texts(\n",
    "    ['이번엔 텍스트 데이터를 추가합니다','추가한 2번째 텍스트 데이터 입니다.'],\n",
    "    metadatas=[{'source':'mydata.txt'},{'source':'mydata.txt'}],\n",
    "    ids = ['del_doc1','del_doc2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['del_doc1', 'del_doc2']\n"
     ]
    }
   ],
   "source": [
    "print(del_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 삭제\n",
    "db.delete(del_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '30f12a86-0926-4fe0-955e-26d1a443bacc',\n",
       " 1: '5f8c14b7-2249-4ce0-a208-7c3f4bbadcb9',\n",
       " 2: '4bacaf7e-dfac-45c5-8621-ad2f915d6375',\n",
       " 3: 'b3baddc4-34cb-4f47-ae1b-2f69ee3c65c2',\n",
       " 4: '930fec7c-9c68-48fa-ac3d-fdaaa8a71b17',\n",
       " 5: '74b21bf4-357a-432b-a1cd-0778e3a0bef8',\n",
       " 6: '3db0c5da-f195-46ce-9b69-5c6070b8db01',\n",
       " 7: '46436281-4812-4ae7-a9a7-17acfee33b54',\n",
       " 8: 'f1e891c0-b1c9-46d6-b4e7-424e89e3d475',\n",
       " 9: 'a321a763-01d2-4861-96a9-82da1f76d8dd',\n",
       " 10: 'f93ba595-6a59-4fba-935b-88463cc37dea',\n",
       " 11: '9a69641b-f542-4e10-be9c-8dbbbc8bc843',\n",
       " 12: '06509079-68c8-4c12-9e58-71336718cf31',\n",
       " 13: '53263ce5-5686-4a1b-a7d7-1ebbe3fc6ee7',\n",
       " 14: 'b879ee1e-617a-44cc-ac2b-a637e2f23273',\n",
       " 15: 'fb6fda78-b54f-4b38-a0e2-99f4f8d93e1a',\n",
       " 16: '2e1bf514-1dea-45fd-9e59-58f387cae09a',\n",
       " 17: 'cce76cc8-47eb-4a70-81a0-b5a06329aa6b',\n",
       " 18: '47230d53-502f-4e87-871c-88849f65db54',\n",
       " 19: '526c1317-e937-4b77-aa37-3ea8070990f6',\n",
       " 20: 'c6a0610e-e679-4c59-8304-16d953578723',\n",
       " 21: '7c3e0f78-128e-422b-b147-3d956f760402',\n",
       " 22: '98c6d7bf-39e5-4933-b052-2d18a4874f86',\n",
       " 23: '26bfc631-24f9-413f-bbd6-f0ea4be38397',\n",
       " 24: '3eb2bd16-fb4c-4c35-99eb-f016c4e0add1',\n",
       " 25: '409cdec5-652d-4e15-9e2d-df197f9f500d',\n",
       " 26: '5851c9b3-9dfd-4c4b-b6e6-35bc47f8762b',\n",
       " 27: '0e61fa27-4bb8-42fe-ae6f-003c707fe5f3',\n",
       " 28: '0354776b-4039-495a-a84a-9febff9ec992',\n",
       " 29: '6042bc07-0f31-4a2a-836d-0d9b5267b54d',\n",
       " 30: '271204df-ce76-4d20-8511-0cc0794141f8',\n",
       " 31: '8b85ca64-b5b7-431c-87c1-28a7a3d956ce',\n",
       " 32: 'a194547a-87fd-485b-ad4e-8b53e5e8224c',\n",
       " 33: 'e4789242-4e34-47ea-8df6-60e96a81b3ed',\n",
       " 34: '5a51a475-f005-4e45-afea-8c1e9c352405',\n",
       " 35: '98c963c9-43a5-4bed-984c-78fc761c0431',\n",
       " 36: '15272b50-6686-4c34-921f-b80189b3c7ac',\n",
       " 37: '4193d2a6-e19e-480e-afb5-b6ea71babfa4',\n",
       " 38: '010a345c-c890-4032-9e2d-321d610a0c67',\n",
       " 39: 'cae1d444-9d6b-4b3e-8a83-c6bc583c67df',\n",
       " 40: '8bd97f16-bb68-43e0-ae95-e104e0cbfe72',\n",
       " 41: '99c0cd26-1dff-488e-bb8a-4276f3b83559',\n",
       " 42: 'a9c93885-d9ed-496f-bbb8-b4fdaff6d402',\n",
       " 43: 'ea3347c4-f871-4a94-acc5-693ae9d61ee7',\n",
       " 44: '3de48a29-762e-4d0c-b7db-2496cb6f6156',\n",
       " 45: '69c2a32f-23b9-4f98-9417-f872eebc6712',\n",
       " 46: 'ef39b89c-f439-40f0-8298-8dbf0907ea8c',\n",
       " 47: 'b9f5e175-8133-4898-885d-629976b1c07a',\n",
       " 48: 'c778ebdc-8ca6-464d-afac-8689147c2f59',\n",
       " 49: '189637d7-f901-4890-8bbb-3f0d3473ca63',\n",
       " 50: '25420f0e-2363-41ea-bb04-203bebccc472',\n",
       " 51: '96ef1900-88e4-4e3d-9b2b-2dae83ae58ba',\n",
       " 52: 'd8562702-64cb-4281-a333-1f9bc1944af6',\n",
       " 53: '8df64439-efa8-4f14-b7cf-e7e29f39515a',\n",
       " 54: 'e6965448-9792-4e09-953a-162a7450811a',\n",
       " 55: '19d9399f-b6f8-475d-88c9-35e3265f5195',\n",
       " 56: '88a9b3c3-f683-4a63-b04f-dfeca6c62057',\n",
       " 57: '569cab06-a98e-4106-a34c-675b11b97229',\n",
       " 58: '5482f8f9-b95c-476b-81e6-5b603c9832b2',\n",
       " 59: '4934eeb9-3ec2-4a62-8ab5-cb965b789265',\n",
       " 60: '2807fe19-dfcf-45ba-a52a-b9341a92ee60',\n",
       " 61: '19705242-5e35-4022-8a72-0723a09dbbc8',\n",
       " 62: '26eff41b-65fd-4a93-9487-67f0bbcb235c',\n",
       " 63: '7879f2f3-2790-41a5-b2ca-a7bb15094b1c',\n",
       " 64: '43366f3e-5073-4977-bab7-4b94de4266bb',\n",
       " 65: 'c0fa13fe-0a8d-44ac-bb43-b2b18fc497ce',\n",
       " 66: '0291909c-9c5c-4f43-acac-94043e8abde8',\n",
       " 67: 'f86a805d-5a6f-4e05-833f-34616ffd14b8',\n",
       " 68: 'c70613d9-1143-42c0-aa02-d68303c3322f',\n",
       " 69: '5b992f14-e7e9-4093-9169-e93ca3a08b6e',\n",
       " 70: '9d96bf1e-c5b0-4e5e-a88c-63ab99ffca38',\n",
       " 71: '845a146d-a113-4174-a1c1-f9e28023ddea',\n",
       " 72: '0b52dffe-1c76-4ae3-9e09-555011bf3edc',\n",
       " 73: '60dfc849-c0be-481f-a67a-e873dcc0b2c9',\n",
       " 74: 'a9a6aa44-4920-4b99-9973-07ff4d8cbadd',\n",
       " 75: '9b74d8f9-b68c-489f-8605-f54a06555559',\n",
       " 76: 'bf293bc4-ca64-48e5-a9ac-307616e5e1a1',\n",
       " 77: 'f3cb401c-66de-4891-ab17-447fe4eba8f6',\n",
       " 78: 'c5e00ed6-3bc1-419f-95db-b441fe0aa0f5',\n",
       " 79: 'c02c30da-2cf8-413a-84fa-77980c7c0a8f',\n",
       " 80: '22ca602f-54ac-4e22-8fd5-254c94d4f5ae',\n",
       " 81: '175a435c-7761-4d1e-a85f-efd767932330',\n",
       " 82: '29038ade-a124-4464-899f-e35ae6dfb989',\n",
       " 83: '66a32654-d05e-48b0-bb8f-8d4fda72e126',\n",
       " 84: '0bf47069-1ddc-436f-bf18-42dc0c102523',\n",
       " 85: '492d424a-0ddf-4055-a7e9-caa52d7b8bfb',\n",
       " 86: '18e1b971-0b22-4031-ae43-fd2b7f620c91',\n",
       " 87: '62093228-a180-4efa-afce-a8b02aefa32d',\n",
       " 88: 'bdb65684-4da4-4dc0-8ebb-2a22df63d64c',\n",
       " 89: '4d9d25cf-5edc-450f-92ad-38810ae8759b',\n",
       " 90: 'bc2cf47d-9ab5-4416-96a7-04466980696e',\n",
       " 91: '3c9b96ba-f259-4bb9-b2e5-eb28c7264326',\n",
       " 92: '0836cf47-1c44-46e6-9775-6e67473385eb',\n",
       " 93: '95f4048c-8431-46c9-b3c4-76dc015735f2',\n",
       " 94: 'bd855735-bab2-4457-a94b-54703e154579',\n",
       " 95: '184f858d-94c6-44d7-a17f-8dab261fa072',\n",
       " 96: 'ad235481-c459-466d-8e00-dd22a5d0e16b',\n",
       " 97: 'e5310b95-af53-48b4-a460-2e9db00138cd',\n",
       " 98: '74053538-ed89-4874-84f8-c9953bd19796',\n",
       " 99: '5cff24c0-6c33-4733-a6de-209734310804',\n",
       " 100: '5e258043-8bb5-435b-aa5d-9c91069c27c4',\n",
       " 101: 'new_doc1',\n",
       " 102: 'new_doc2',\n",
       " 103: 'new_doc3'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local db 저장\n",
    "db.save_local(folder_path='faiss_db', index_name= 'faiss_index')\n",
    "# 폴더명 , 인덱스 네임(파일이름)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local에 저장된 db불러오기\n",
    "loaded_db = FAISS.load_local(\n",
    "    folder_path='faiss_db',\n",
    "    index_name='faiss_index',\n",
    "    embeddings = embeddings,\n",
    "    allow_dangerous_deserialization= True\n",
    "    # 역직렬화 json 형태 등을 이야기함 . 원래 데이터로 돌릴 것이다 => 파이썬 객체로 변경한다\n",
    "    # 테이터 손실의 위험성을 알고 있지만 동의하고 불러올거라고 선언\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '30f12a86-0926-4fe0-955e-26d1a443bacc',\n",
       " 1: '5f8c14b7-2249-4ce0-a208-7c3f4bbadcb9',\n",
       " 2: '4bacaf7e-dfac-45c5-8621-ad2f915d6375',\n",
       " 3: 'b3baddc4-34cb-4f47-ae1b-2f69ee3c65c2',\n",
       " 4: '930fec7c-9c68-48fa-ac3d-fdaaa8a71b17',\n",
       " 5: '74b21bf4-357a-432b-a1cd-0778e3a0bef8',\n",
       " 6: '3db0c5da-f195-46ce-9b69-5c6070b8db01',\n",
       " 7: '46436281-4812-4ae7-a9a7-17acfee33b54',\n",
       " 8: 'f1e891c0-b1c9-46d6-b4e7-424e89e3d475',\n",
       " 9: 'a321a763-01d2-4861-96a9-82da1f76d8dd',\n",
       " 10: 'f93ba595-6a59-4fba-935b-88463cc37dea',\n",
       " 11: '9a69641b-f542-4e10-be9c-8dbbbc8bc843',\n",
       " 12: '06509079-68c8-4c12-9e58-71336718cf31',\n",
       " 13: '53263ce5-5686-4a1b-a7d7-1ebbe3fc6ee7',\n",
       " 14: 'b879ee1e-617a-44cc-ac2b-a637e2f23273',\n",
       " 15: 'fb6fda78-b54f-4b38-a0e2-99f4f8d93e1a',\n",
       " 16: '2e1bf514-1dea-45fd-9e59-58f387cae09a',\n",
       " 17: 'cce76cc8-47eb-4a70-81a0-b5a06329aa6b',\n",
       " 18: '47230d53-502f-4e87-871c-88849f65db54',\n",
       " 19: '526c1317-e937-4b77-aa37-3ea8070990f6',\n",
       " 20: 'c6a0610e-e679-4c59-8304-16d953578723',\n",
       " 21: '7c3e0f78-128e-422b-b147-3d956f760402',\n",
       " 22: '98c6d7bf-39e5-4933-b052-2d18a4874f86',\n",
       " 23: '26bfc631-24f9-413f-bbd6-f0ea4be38397',\n",
       " 24: '3eb2bd16-fb4c-4c35-99eb-f016c4e0add1',\n",
       " 25: '409cdec5-652d-4e15-9e2d-df197f9f500d',\n",
       " 26: '5851c9b3-9dfd-4c4b-b6e6-35bc47f8762b',\n",
       " 27: '0e61fa27-4bb8-42fe-ae6f-003c707fe5f3',\n",
       " 28: '0354776b-4039-495a-a84a-9febff9ec992',\n",
       " 29: '6042bc07-0f31-4a2a-836d-0d9b5267b54d',\n",
       " 30: '271204df-ce76-4d20-8511-0cc0794141f8',\n",
       " 31: '8b85ca64-b5b7-431c-87c1-28a7a3d956ce',\n",
       " 32: 'a194547a-87fd-485b-ad4e-8b53e5e8224c',\n",
       " 33: 'e4789242-4e34-47ea-8df6-60e96a81b3ed',\n",
       " 34: '5a51a475-f005-4e45-afea-8c1e9c352405',\n",
       " 35: '98c963c9-43a5-4bed-984c-78fc761c0431',\n",
       " 36: '15272b50-6686-4c34-921f-b80189b3c7ac',\n",
       " 37: '4193d2a6-e19e-480e-afb5-b6ea71babfa4',\n",
       " 38: '010a345c-c890-4032-9e2d-321d610a0c67',\n",
       " 39: 'cae1d444-9d6b-4b3e-8a83-c6bc583c67df',\n",
       " 40: '8bd97f16-bb68-43e0-ae95-e104e0cbfe72',\n",
       " 41: '99c0cd26-1dff-488e-bb8a-4276f3b83559',\n",
       " 42: 'a9c93885-d9ed-496f-bbb8-b4fdaff6d402',\n",
       " 43: 'ea3347c4-f871-4a94-acc5-693ae9d61ee7',\n",
       " 44: '3de48a29-762e-4d0c-b7db-2496cb6f6156',\n",
       " 45: '69c2a32f-23b9-4f98-9417-f872eebc6712',\n",
       " 46: 'ef39b89c-f439-40f0-8298-8dbf0907ea8c',\n",
       " 47: 'b9f5e175-8133-4898-885d-629976b1c07a',\n",
       " 48: 'c778ebdc-8ca6-464d-afac-8689147c2f59',\n",
       " 49: '189637d7-f901-4890-8bbb-3f0d3473ca63',\n",
       " 50: '25420f0e-2363-41ea-bb04-203bebccc472',\n",
       " 51: '96ef1900-88e4-4e3d-9b2b-2dae83ae58ba',\n",
       " 52: 'd8562702-64cb-4281-a333-1f9bc1944af6',\n",
       " 53: '8df64439-efa8-4f14-b7cf-e7e29f39515a',\n",
       " 54: 'e6965448-9792-4e09-953a-162a7450811a',\n",
       " 55: '19d9399f-b6f8-475d-88c9-35e3265f5195',\n",
       " 56: '88a9b3c3-f683-4a63-b04f-dfeca6c62057',\n",
       " 57: '569cab06-a98e-4106-a34c-675b11b97229',\n",
       " 58: '5482f8f9-b95c-476b-81e6-5b603c9832b2',\n",
       " 59: '4934eeb9-3ec2-4a62-8ab5-cb965b789265',\n",
       " 60: '2807fe19-dfcf-45ba-a52a-b9341a92ee60',\n",
       " 61: '19705242-5e35-4022-8a72-0723a09dbbc8',\n",
       " 62: '26eff41b-65fd-4a93-9487-67f0bbcb235c',\n",
       " 63: '7879f2f3-2790-41a5-b2ca-a7bb15094b1c',\n",
       " 64: '43366f3e-5073-4977-bab7-4b94de4266bb',\n",
       " 65: 'c0fa13fe-0a8d-44ac-bb43-b2b18fc497ce',\n",
       " 66: '0291909c-9c5c-4f43-acac-94043e8abde8',\n",
       " 67: 'f86a805d-5a6f-4e05-833f-34616ffd14b8',\n",
       " 68: 'c70613d9-1143-42c0-aa02-d68303c3322f',\n",
       " 69: '5b992f14-e7e9-4093-9169-e93ca3a08b6e',\n",
       " 70: '9d96bf1e-c5b0-4e5e-a88c-63ab99ffca38',\n",
       " 71: '845a146d-a113-4174-a1c1-f9e28023ddea',\n",
       " 72: '0b52dffe-1c76-4ae3-9e09-555011bf3edc',\n",
       " 73: '60dfc849-c0be-481f-a67a-e873dcc0b2c9',\n",
       " 74: 'a9a6aa44-4920-4b99-9973-07ff4d8cbadd',\n",
       " 75: '9b74d8f9-b68c-489f-8605-f54a06555559',\n",
       " 76: 'bf293bc4-ca64-48e5-a9ac-307616e5e1a1',\n",
       " 77: 'f3cb401c-66de-4891-ab17-447fe4eba8f6',\n",
       " 78: 'c5e00ed6-3bc1-419f-95db-b441fe0aa0f5',\n",
       " 79: 'c02c30da-2cf8-413a-84fa-77980c7c0a8f',\n",
       " 80: '22ca602f-54ac-4e22-8fd5-254c94d4f5ae',\n",
       " 81: '175a435c-7761-4d1e-a85f-efd767932330',\n",
       " 82: '29038ade-a124-4464-899f-e35ae6dfb989',\n",
       " 83: '66a32654-d05e-48b0-bb8f-8d4fda72e126',\n",
       " 84: '0bf47069-1ddc-436f-bf18-42dc0c102523',\n",
       " 85: '492d424a-0ddf-4055-a7e9-caa52d7b8bfb',\n",
       " 86: '18e1b971-0b22-4031-ae43-fd2b7f620c91',\n",
       " 87: '62093228-a180-4efa-afce-a8b02aefa32d',\n",
       " 88: 'bdb65684-4da4-4dc0-8ebb-2a22df63d64c',\n",
       " 89: '4d9d25cf-5edc-450f-92ad-38810ae8759b',\n",
       " 90: 'bc2cf47d-9ab5-4416-96a7-04466980696e',\n",
       " 91: '3c9b96ba-f259-4bb9-b2e5-eb28c7264326',\n",
       " 92: '0836cf47-1c44-46e6-9775-6e67473385eb',\n",
       " 93: '95f4048c-8431-46c9-b3c4-76dc015735f2',\n",
       " 94: 'bd855735-bab2-4457-a94b-54703e154579',\n",
       " 95: '184f858d-94c6-44d7-a17f-8dab261fa072',\n",
       " 96: 'ad235481-c459-466d-8e00-dd22a5d0e16b',\n",
       " 97: 'e5310b95-af53-48b4-a460-2e9db00138cd',\n",
       " 98: '74053538-ed89-4874-84f8-c9953bd19796',\n",
       " 99: '5cff24c0-6c33-4733-a6de-209734310804',\n",
       " 100: '5e258043-8bb5-435b-aa5d-9c91069c27c4',\n",
       " 101: 'new_doc1',\n",
       " 102: 'new_doc2',\n",
       " 103: 'new_doc3'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_db.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = FAISS.from_documents(documents=split_doc2, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '302223b4-8811-4e35-82c9-a9977491ecef',\n",
       " 1: 'ce75603d-6c6e-485f-bf0e-2db1407e4528',\n",
       " 2: '02700ccb-d782-41a6-9f8a-bca043c9abbe',\n",
       " 3: '23e236c8-4ad1-430b-afe1-e7acbf6f65ee',\n",
       " 4: '205f1719-cea8-4590-9d4f-71d375c8c4c3',\n",
       " 5: 'fc2b88be-a897-4574-98a5-969ec4c2e7e0',\n",
       " 6: 'e357f627-c20d-49f6-bca5-93136ab63c37',\n",
       " 7: 'f682d077-2366-492b-b03d-5b6888bebfa1',\n",
       " 8: '430e90da-7ed3-488f-9af7-2baaee75f1e8',\n",
       " 9: 'df4832cf-113e-4b0f-a4f9-885d94459bac',\n",
       " 10: '7dff9863-87ef-4f66-9b76-6b78d3d7c59b',\n",
       " 11: '01e966d5-905c-4c0c-810c-8d3ec221a9bf',\n",
       " 12: '099eaa74-0606-46da-8c02-d3e5772ec8d6',\n",
       " 13: '9fbe9560-3eab-48ab-949c-d1edc8a557bd',\n",
       " 14: '80c0e66c-685e-424c-b7c9-c1511104a238',\n",
       " 15: '87423d0e-df36-4cd6-991b-a382605aa92e',\n",
       " 16: '5d9d1265-b317-4865-8419-aabcf7941798',\n",
       " 17: 'cff9aa5f-2b5b-41c5-95e0-4378c44c39be',\n",
       " 18: 'f38923c3-6aeb-48d8-aca3-29174abb3850',\n",
       " 19: '5efb46e6-b469-42f9-aee8-c02b987660fd',\n",
       " 20: 'e42c1eac-f42f-4c92-8590-efdba9207cc0',\n",
       " 21: '192381ab-9e36-4bb6-a200-fb811e08588e',\n",
       " 22: 'baf27372-89bf-40ce-9e99-03b02ec1cd21',\n",
       " 23: '5903467e-e444-4048-aa44-4520e732878b',\n",
       " 24: '792ce3de-9969-4351-b627-e3733171144f',\n",
       " 25: '326c6bff-eb7b-464e-a1da-85a7daf757b2',\n",
       " 26: '8e447e7f-7345-4d1d-9868-f8512d9c0c43',\n",
       " 27: 'c8d210a7-2d8b-430a-b560-6d431c26f19c',\n",
       " 28: 'f51f258c-0cc1-4c13-a5e7-1c006b596c1c',\n",
       " 29: '294a19b7-b016-41a2-a63d-2e7624ef3c99',\n",
       " 30: '9379a865-7997-4876-9fa2-056986cec469',\n",
       " 31: '5b8fb83d-61ec-4342-9eaa-0ce7633c6adb',\n",
       " 32: '8934f213-b68e-4a91-8007-b8fa6313d8ef',\n",
       " 33: '16bb1e8a-1fb0-41ce-8bd0-9858047c6156',\n",
       " 34: 'f5c4a119-d5b4-4d66-9373-50f8971e35ba',\n",
       " 35: '8d9f94f0-dfd2-44b3-a5c1-c93cd6eb6fe4',\n",
       " 36: '87315cf2-3ccb-4e71-82f8-894c0173a78d',\n",
       " 37: '2f09ca6c-b296-4c78-b083-5efbfbc3c45d',\n",
       " 38: 'fb44388d-3284-4e08-8c34-f185a695e920',\n",
       " 39: '233b64e6-e64f-427b-898b-9c436c1efaa4',\n",
       " 40: 'b1747cf3-a7c3-4a27-8166-87e3d441756f',\n",
       " 41: 'd03b5832-0e1a-448e-b561-1d127658769a',\n",
       " 42: 'd1bd2e14-3f21-4860-a993-4e68ff78b53d',\n",
       " 43: 'c335afbb-af5e-431b-9830-c912f39b7629',\n",
       " 44: '30a5e2a4-d5a7-445d-a27d-91f567c73080',\n",
       " 45: 'f8c096b2-1021-472b-ae13-0d60065dd724',\n",
       " 46: '66bec303-d70a-40c1-a9cf-8ba60a91a830',\n",
       " 47: 'b7fa8afa-0894-4fc5-b4cb-888c1c20bbdb',\n",
       " 48: 'bbc9768e-ebf2-43e6-85fa-5274afae488b',\n",
       " 49: '4c146316-80d4-4633-877f-9f15e1af0380',\n",
       " 50: 'e23db688-259d-445b-b879-b6beb448ae7d',\n",
       " 51: 'a9d304eb-6ecd-483c-a860-1a1049ff9c0b',\n",
       " 52: 'fcacdff8-8871-4eb9-bf99-0a783bd09859',\n",
       " 53: 'b069aecd-6b4e-4158-b640-9a08b59e9891',\n",
       " 54: '6ac809e4-7c2d-4b69-8a28-dc3e6b247589',\n",
       " 55: 'b205f8b6-5f81-42fe-848a-0d323a8ea76b',\n",
       " 56: 'bad60418-11cb-4680-adf6-0f3e08065b0d',\n",
       " 57: 'e8e4645d-8467-4390-b9d5-8038d25c2413',\n",
       " 58: '82e35de0-c260-4ce4-a7cc-7fca10645ffa',\n",
       " 59: '197bb3a8-9b12-4cab-9a56-59aa12a2569c'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.merge_from(db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '30f12a86-0926-4fe0-955e-26d1a443bacc',\n",
       " 1: '5f8c14b7-2249-4ce0-a208-7c3f4bbadcb9',\n",
       " 2: '4bacaf7e-dfac-45c5-8621-ad2f915d6375',\n",
       " 3: 'b3baddc4-34cb-4f47-ae1b-2f69ee3c65c2',\n",
       " 4: '930fec7c-9c68-48fa-ac3d-fdaaa8a71b17',\n",
       " 5: '74b21bf4-357a-432b-a1cd-0778e3a0bef8',\n",
       " 6: '3db0c5da-f195-46ce-9b69-5c6070b8db01',\n",
       " 7: '46436281-4812-4ae7-a9a7-17acfee33b54',\n",
       " 8: 'f1e891c0-b1c9-46d6-b4e7-424e89e3d475',\n",
       " 9: 'a321a763-01d2-4861-96a9-82da1f76d8dd',\n",
       " 10: 'f93ba595-6a59-4fba-935b-88463cc37dea',\n",
       " 11: '9a69641b-f542-4e10-be9c-8dbbbc8bc843',\n",
       " 12: '06509079-68c8-4c12-9e58-71336718cf31',\n",
       " 13: '53263ce5-5686-4a1b-a7d7-1ebbe3fc6ee7',\n",
       " 14: 'b879ee1e-617a-44cc-ac2b-a637e2f23273',\n",
       " 15: 'fb6fda78-b54f-4b38-a0e2-99f4f8d93e1a',\n",
       " 16: '2e1bf514-1dea-45fd-9e59-58f387cae09a',\n",
       " 17: 'cce76cc8-47eb-4a70-81a0-b5a06329aa6b',\n",
       " 18: '47230d53-502f-4e87-871c-88849f65db54',\n",
       " 19: '526c1317-e937-4b77-aa37-3ea8070990f6',\n",
       " 20: 'c6a0610e-e679-4c59-8304-16d953578723',\n",
       " 21: '7c3e0f78-128e-422b-b147-3d956f760402',\n",
       " 22: '98c6d7bf-39e5-4933-b052-2d18a4874f86',\n",
       " 23: '26bfc631-24f9-413f-bbd6-f0ea4be38397',\n",
       " 24: '3eb2bd16-fb4c-4c35-99eb-f016c4e0add1',\n",
       " 25: '409cdec5-652d-4e15-9e2d-df197f9f500d',\n",
       " 26: '5851c9b3-9dfd-4c4b-b6e6-35bc47f8762b',\n",
       " 27: '0e61fa27-4bb8-42fe-ae6f-003c707fe5f3',\n",
       " 28: '0354776b-4039-495a-a84a-9febff9ec992',\n",
       " 29: '6042bc07-0f31-4a2a-836d-0d9b5267b54d',\n",
       " 30: '271204df-ce76-4d20-8511-0cc0794141f8',\n",
       " 31: '8b85ca64-b5b7-431c-87c1-28a7a3d956ce',\n",
       " 32: 'a194547a-87fd-485b-ad4e-8b53e5e8224c',\n",
       " 33: 'e4789242-4e34-47ea-8df6-60e96a81b3ed',\n",
       " 34: '5a51a475-f005-4e45-afea-8c1e9c352405',\n",
       " 35: '98c963c9-43a5-4bed-984c-78fc761c0431',\n",
       " 36: '15272b50-6686-4c34-921f-b80189b3c7ac',\n",
       " 37: '4193d2a6-e19e-480e-afb5-b6ea71babfa4',\n",
       " 38: '010a345c-c890-4032-9e2d-321d610a0c67',\n",
       " 39: 'cae1d444-9d6b-4b3e-8a83-c6bc583c67df',\n",
       " 40: '8bd97f16-bb68-43e0-ae95-e104e0cbfe72',\n",
       " 41: '99c0cd26-1dff-488e-bb8a-4276f3b83559',\n",
       " 42: 'a9c93885-d9ed-496f-bbb8-b4fdaff6d402',\n",
       " 43: 'ea3347c4-f871-4a94-acc5-693ae9d61ee7',\n",
       " 44: '3de48a29-762e-4d0c-b7db-2496cb6f6156',\n",
       " 45: '69c2a32f-23b9-4f98-9417-f872eebc6712',\n",
       " 46: 'ef39b89c-f439-40f0-8298-8dbf0907ea8c',\n",
       " 47: 'b9f5e175-8133-4898-885d-629976b1c07a',\n",
       " 48: 'c778ebdc-8ca6-464d-afac-8689147c2f59',\n",
       " 49: '189637d7-f901-4890-8bbb-3f0d3473ca63',\n",
       " 50: '25420f0e-2363-41ea-bb04-203bebccc472',\n",
       " 51: '96ef1900-88e4-4e3d-9b2b-2dae83ae58ba',\n",
       " 52: 'd8562702-64cb-4281-a333-1f9bc1944af6',\n",
       " 53: '8df64439-efa8-4f14-b7cf-e7e29f39515a',\n",
       " 54: 'e6965448-9792-4e09-953a-162a7450811a',\n",
       " 55: '19d9399f-b6f8-475d-88c9-35e3265f5195',\n",
       " 56: '88a9b3c3-f683-4a63-b04f-dfeca6c62057',\n",
       " 57: '569cab06-a98e-4106-a34c-675b11b97229',\n",
       " 58: '5482f8f9-b95c-476b-81e6-5b603c9832b2',\n",
       " 59: '4934eeb9-3ec2-4a62-8ab5-cb965b789265',\n",
       " 60: '2807fe19-dfcf-45ba-a52a-b9341a92ee60',\n",
       " 61: '19705242-5e35-4022-8a72-0723a09dbbc8',\n",
       " 62: '26eff41b-65fd-4a93-9487-67f0bbcb235c',\n",
       " 63: '7879f2f3-2790-41a5-b2ca-a7bb15094b1c',\n",
       " 64: '43366f3e-5073-4977-bab7-4b94de4266bb',\n",
       " 65: 'c0fa13fe-0a8d-44ac-bb43-b2b18fc497ce',\n",
       " 66: '0291909c-9c5c-4f43-acac-94043e8abde8',\n",
       " 67: 'f86a805d-5a6f-4e05-833f-34616ffd14b8',\n",
       " 68: 'c70613d9-1143-42c0-aa02-d68303c3322f',\n",
       " 69: '5b992f14-e7e9-4093-9169-e93ca3a08b6e',\n",
       " 70: '9d96bf1e-c5b0-4e5e-a88c-63ab99ffca38',\n",
       " 71: '845a146d-a113-4174-a1c1-f9e28023ddea',\n",
       " 72: '0b52dffe-1c76-4ae3-9e09-555011bf3edc',\n",
       " 73: '60dfc849-c0be-481f-a67a-e873dcc0b2c9',\n",
       " 74: 'a9a6aa44-4920-4b99-9973-07ff4d8cbadd',\n",
       " 75: '9b74d8f9-b68c-489f-8605-f54a06555559',\n",
       " 76: 'bf293bc4-ca64-48e5-a9ac-307616e5e1a1',\n",
       " 77: 'f3cb401c-66de-4891-ab17-447fe4eba8f6',\n",
       " 78: 'c5e00ed6-3bc1-419f-95db-b441fe0aa0f5',\n",
       " 79: 'c02c30da-2cf8-413a-84fa-77980c7c0a8f',\n",
       " 80: '22ca602f-54ac-4e22-8fd5-254c94d4f5ae',\n",
       " 81: '175a435c-7761-4d1e-a85f-efd767932330',\n",
       " 82: '29038ade-a124-4464-899f-e35ae6dfb989',\n",
       " 83: '66a32654-d05e-48b0-bb8f-8d4fda72e126',\n",
       " 84: '0bf47069-1ddc-436f-bf18-42dc0c102523',\n",
       " 85: '492d424a-0ddf-4055-a7e9-caa52d7b8bfb',\n",
       " 86: '18e1b971-0b22-4031-ae43-fd2b7f620c91',\n",
       " 87: '62093228-a180-4efa-afce-a8b02aefa32d',\n",
       " 88: 'bdb65684-4da4-4dc0-8ebb-2a22df63d64c',\n",
       " 89: '4d9d25cf-5edc-450f-92ad-38810ae8759b',\n",
       " 90: 'bc2cf47d-9ab5-4416-96a7-04466980696e',\n",
       " 91: '3c9b96ba-f259-4bb9-b2e5-eb28c7264326',\n",
       " 92: '0836cf47-1c44-46e6-9775-6e67473385eb',\n",
       " 93: '95f4048c-8431-46c9-b3c4-76dc015735f2',\n",
       " 94: 'bd855735-bab2-4457-a94b-54703e154579',\n",
       " 95: '184f858d-94c6-44d7-a17f-8dab261fa072',\n",
       " 96: 'ad235481-c459-466d-8e00-dd22a5d0e16b',\n",
       " 97: 'e5310b95-af53-48b4-a460-2e9db00138cd',\n",
       " 98: '74053538-ed89-4874-84f8-c9953bd19796',\n",
       " 99: '5cff24c0-6c33-4733-a6de-209734310804',\n",
       " 100: '5e258043-8bb5-435b-aa5d-9c91069c27c4',\n",
       " 101: 'new_doc1',\n",
       " 102: 'new_doc2',\n",
       " 103: 'new_doc3',\n",
       " 104: '302223b4-8811-4e35-82c9-a9977491ecef',\n",
       " 105: 'ce75603d-6c6e-485f-bf0e-2db1407e4528',\n",
       " 106: '02700ccb-d782-41a6-9f8a-bca043c9abbe',\n",
       " 107: '23e236c8-4ad1-430b-afe1-e7acbf6f65ee',\n",
       " 108: '205f1719-cea8-4590-9d4f-71d375c8c4c3',\n",
       " 109: 'fc2b88be-a897-4574-98a5-969ec4c2e7e0',\n",
       " 110: 'e357f627-c20d-49f6-bca5-93136ab63c37',\n",
       " 111: 'f682d077-2366-492b-b03d-5b6888bebfa1',\n",
       " 112: '430e90da-7ed3-488f-9af7-2baaee75f1e8',\n",
       " 113: 'df4832cf-113e-4b0f-a4f9-885d94459bac',\n",
       " 114: '7dff9863-87ef-4f66-9b76-6b78d3d7c59b',\n",
       " 115: '01e966d5-905c-4c0c-810c-8d3ec221a9bf',\n",
       " 116: '099eaa74-0606-46da-8c02-d3e5772ec8d6',\n",
       " 117: '9fbe9560-3eab-48ab-949c-d1edc8a557bd',\n",
       " 118: '80c0e66c-685e-424c-b7c9-c1511104a238',\n",
       " 119: '87423d0e-df36-4cd6-991b-a382605aa92e',\n",
       " 120: '5d9d1265-b317-4865-8419-aabcf7941798',\n",
       " 121: 'cff9aa5f-2b5b-41c5-95e0-4378c44c39be',\n",
       " 122: 'f38923c3-6aeb-48d8-aca3-29174abb3850',\n",
       " 123: '5efb46e6-b469-42f9-aee8-c02b987660fd',\n",
       " 124: 'e42c1eac-f42f-4c92-8590-efdba9207cc0',\n",
       " 125: '192381ab-9e36-4bb6-a200-fb811e08588e',\n",
       " 126: 'baf27372-89bf-40ce-9e99-03b02ec1cd21',\n",
       " 127: '5903467e-e444-4048-aa44-4520e732878b',\n",
       " 128: '792ce3de-9969-4351-b627-e3733171144f',\n",
       " 129: '326c6bff-eb7b-464e-a1da-85a7daf757b2',\n",
       " 130: '8e447e7f-7345-4d1d-9868-f8512d9c0c43',\n",
       " 131: 'c8d210a7-2d8b-430a-b560-6d431c26f19c',\n",
       " 132: 'f51f258c-0cc1-4c13-a5e7-1c006b596c1c',\n",
       " 133: '294a19b7-b016-41a2-a63d-2e7624ef3c99',\n",
       " 134: '9379a865-7997-4876-9fa2-056986cec469',\n",
       " 135: '5b8fb83d-61ec-4342-9eaa-0ce7633c6adb',\n",
       " 136: '8934f213-b68e-4a91-8007-b8fa6313d8ef',\n",
       " 137: '16bb1e8a-1fb0-41ce-8bd0-9858047c6156',\n",
       " 138: 'f5c4a119-d5b4-4d66-9373-50f8971e35ba',\n",
       " 139: '8d9f94f0-dfd2-44b3-a5c1-c93cd6eb6fe4',\n",
       " 140: '87315cf2-3ccb-4e71-82f8-894c0173a78d',\n",
       " 141: '2f09ca6c-b296-4c78-b083-5efbfbc3c45d',\n",
       " 142: 'fb44388d-3284-4e08-8c34-f185a695e920',\n",
       " 143: '233b64e6-e64f-427b-898b-9c436c1efaa4',\n",
       " 144: 'b1747cf3-a7c3-4a27-8166-87e3d441756f',\n",
       " 145: 'd03b5832-0e1a-448e-b561-1d127658769a',\n",
       " 146: 'd1bd2e14-3f21-4860-a993-4e68ff78b53d',\n",
       " 147: 'c335afbb-af5e-431b-9830-c912f39b7629',\n",
       " 148: '30a5e2a4-d5a7-445d-a27d-91f567c73080',\n",
       " 149: 'f8c096b2-1021-472b-ae13-0d60065dd724',\n",
       " 150: '66bec303-d70a-40c1-a9cf-8ba60a91a830',\n",
       " 151: 'b7fa8afa-0894-4fc5-b4cb-888c1c20bbdb',\n",
       " 152: 'bbc9768e-ebf2-43e6-85fa-5274afae488b',\n",
       " 153: '4c146316-80d4-4633-877f-9f15e1af0380',\n",
       " 154: 'e23db688-259d-445b-b879-b6beb448ae7d',\n",
       " 155: 'a9d304eb-6ecd-483c-a860-1a1049ff9c0b',\n",
       " 156: 'fcacdff8-8871-4eb9-bf99-0a783bd09859',\n",
       " 157: 'b069aecd-6b4e-4158-b640-9a08b59e9891',\n",
       " 158: '6ac809e4-7c2d-4b69-8a28-dc3e6b247589',\n",
       " 159: 'b205f8b6-5f81-42fe-848a-0d323a8ea76b',\n",
       " 160: 'bad60418-11cb-4680-adf6-0f3e08065b0d',\n",
       " 161: 'e8e4645d-8467-4390-b9d5-8038d25c2413',\n",
       " 162: '82e35de0-c260-4ce4-a7cc-7fca10645ffa',\n",
       " 163: '197bb3a8-9b12-4cab-9a56-59aa12a2569c'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index_to_docstore_id\n",
    "# 101 + 3(추가데이터) + 60(merge데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(\n",
    "    documents= split_doc1 + split_doc2, embedding = OpenAIEmbeddings()\n",
    "    # 애초에 같이 넣어주기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '2d9f0c80-8bc3-4893-8890-13cfaa758e72',\n",
       " 1: 'd398776c-bec2-480d-8f7f-befb66a8ca8d',\n",
       " 2: '101588fd-4424-4ace-aeeb-acdcc38f9a91',\n",
       " 3: '84bff100-4671-44d1-87de-cfccaa43d1b9',\n",
       " 4: 'ad6b5dd2-bd5b-47e1-92a5-4563a5e2ab58',\n",
       " 5: '395dfb37-b3c1-4526-9fce-7968ba858f2a',\n",
       " 6: '4f3d1890-aed4-4447-8e16-cb9db0d97633',\n",
       " 7: '65e28610-501e-4d45-81a7-156bfbdc2fcb',\n",
       " 8: '35573270-0a72-47f0-a4e0-b4aa4aa45846',\n",
       " 9: '64767fbd-0c42-477b-84ed-a9d65d736fe2',\n",
       " 10: '52115417-8c71-47f1-bf37-eaf1ad63a7c5',\n",
       " 11: 'bed1a58f-bd3b-4803-9247-d5e69230e9f9',\n",
       " 12: '1e8d887a-2557-4345-8d45-3d155c4de3ac',\n",
       " 13: 'c900b9c6-5c87-4efb-92df-4fbc558749f4',\n",
       " 14: 'a6c701b2-904e-4871-bbd8-0757339fe480',\n",
       " 15: '8c349752-88a5-45ea-be06-831e982976ee',\n",
       " 16: 'c493b8b9-1ccb-4f6e-9b62-da346aa6ce59',\n",
       " 17: 'ef5ba4ad-9d70-4742-bada-1c2b9bebb32e',\n",
       " 18: 'eed9af30-ac95-428c-aadd-d9ba4c1d3352',\n",
       " 19: '870de474-f06f-4ebb-8157-7ea1c80fafaa',\n",
       " 20: '2fd5dbcb-92a5-49c4-9742-328a95fff6f0',\n",
       " 21: 'd39ff1ce-9090-4b14-b436-ee1e56b15f8b',\n",
       " 22: '952bea4d-0141-45f8-be09-61229de9a59b',\n",
       " 23: '11ced8a5-4ea1-4c80-b6b3-0a0c1b9b45d1',\n",
       " 24: 'da73428b-1aba-40d5-b25f-4c77bd35c2e5',\n",
       " 25: '1b0ec99e-ecb4-4f35-8d2b-368e690a67de',\n",
       " 26: 'f3e3ae38-bb46-4041-ae07-5262bb006ad8',\n",
       " 27: '9b45c23e-b79e-4fba-9ebb-c22eba6a5a5f',\n",
       " 28: 'a8d066aa-6c7e-4199-9cb9-0a3fb3c76151',\n",
       " 29: '4d92e21b-9ead-4a0e-8ef0-20769131e407',\n",
       " 30: '263ccef0-014b-4151-9b4d-6206d8e269b2',\n",
       " 31: 'abc33f1f-f669-40c8-972b-24fef2b98e3d',\n",
       " 32: '0b3bcb38-3fea-4bd4-b6e0-9eff0fc908c1',\n",
       " 33: 'a7529998-d97d-4d0b-958c-277685d40005',\n",
       " 34: '368e021a-2241-48dc-91db-5943017da9bb',\n",
       " 35: '88e89208-1f8e-4b2f-83a3-33e76f7853de',\n",
       " 36: '5d1bacbb-dc67-4e83-a288-8f61fe6c5c12',\n",
       " 37: 'cbebd124-52e3-4bda-a179-f7cba925befa',\n",
       " 38: '980ea244-1541-49b6-9827-f6a0239de563',\n",
       " 39: 'af3faf3b-cdd8-48c8-9863-3f95207f7985',\n",
       " 40: '7fa44d54-c10b-441f-b6b1-48b8f070dce6',\n",
       " 41: '821f1960-1540-42d2-b97b-79c24b39ed43',\n",
       " 42: 'da5f52db-7c1a-4c03-ba87-b2cae8dd1ce5',\n",
       " 43: 'dba50142-1f29-4924-8fec-de2e87c57419',\n",
       " 44: '01b89dce-c37d-464c-81d3-a1b6b8a19ea5',\n",
       " 45: '218c43ff-a82f-475f-a343-5bce1d426941',\n",
       " 46: '2fa1702b-b4a0-482e-97e5-c29d85d11d4a',\n",
       " 47: 'd6405232-15f4-468b-b1e4-bb665964e28d',\n",
       " 48: '0fd765d6-d92f-4cd4-8a67-612e1483ae84',\n",
       " 49: '0685c216-0d8f-4ed3-a09c-8e66ce845186',\n",
       " 50: '0a2fcdd7-5ee7-44a2-8eb2-1002e0d02a72',\n",
       " 51: 'a52a3446-0e2e-442c-bd86-8996ecec0ded',\n",
       " 52: 'ee4f01ba-6fb4-4620-bb70-2a36d97efcd1',\n",
       " 53: 'ee1317d8-07e8-41ae-951d-52432c1b85bf',\n",
       " 54: '163f3a80-d113-4092-817b-d2afb7824c6c',\n",
       " 55: 'ef15a2fd-fb1f-4cea-ac9b-ac335f15ea67',\n",
       " 56: '05343151-3054-48ec-b777-8b3bc8cb900b',\n",
       " 57: '5ba4de9b-b105-432c-90b6-890437bb7e4b',\n",
       " 58: 'd9ace628-867a-4f5f-8709-e1f8ceb56186',\n",
       " 59: '57ec24f8-0a56-4982-9d26-ca382a5c0be6',\n",
       " 60: 'f104ee26-3e29-4508-ac8c-cf60e9ceb9de',\n",
       " 61: 'ebc90479-a2bc-4462-9c09-d5bc650f6b0f',\n",
       " 62: 'bebf0eb4-6d30-40d4-8eb2-090d91ade643',\n",
       " 63: '083c39b9-a4ef-422d-9303-255742c96f5c',\n",
       " 64: '89e6a281-81a3-409b-b86f-b7ea5339bb6a',\n",
       " 65: '8a523671-c41e-45bd-aadf-c5566e62aa31',\n",
       " 66: '869dedca-7e89-49f1-adcc-2ffb5f0715c0',\n",
       " 67: 'bd740951-dfac-467c-8bd7-a3ed1a104237',\n",
       " 68: '72877244-fff4-49ec-a09e-7eb2a2c6bd21',\n",
       " 69: 'd4655948-f23e-45ca-820a-f0245b2596c8',\n",
       " 70: '829a0076-d05d-4799-8b01-2e6376db11b0',\n",
       " 71: '3c8cbfe7-0140-436e-b3fe-ef91ebcc234c',\n",
       " 72: '2b850eb6-446a-44d3-87f9-95b9e53d6838',\n",
       " 73: '9b47bac8-614e-43a4-8f5d-48c910e6d700',\n",
       " 74: 'e4851533-5460-4e0d-b1a1-48938506b419',\n",
       " 75: 'd8d30ad1-a47f-4c74-9725-6fa83b29b1c9',\n",
       " 76: '796f49d2-6b74-459c-a82f-cd88fc7c06c2',\n",
       " 77: '95a6e9f9-1d4c-437b-bdd9-6a298a92aec6',\n",
       " 78: '2f936f1c-09dc-4381-af82-5f646f9da6ad',\n",
       " 79: '8c1b3dfa-65db-44c0-9e27-c63531f7b1b8',\n",
       " 80: '84c117a7-3621-4190-8b88-f7df9ea57171',\n",
       " 81: 'c66c64f8-c943-4dd8-9e3c-05a10934e7f7',\n",
       " 82: '7f729b44-6171-4c2a-aa2c-2f2a538e45d5',\n",
       " 83: 'a1b26f9a-9625-421a-9d6d-029c30637f44',\n",
       " 84: '52b8d6c3-ae38-483a-932e-c0bd698bbd84',\n",
       " 85: '69d4324a-c53d-4c2c-94ab-34cff749d521',\n",
       " 86: '7269763b-afa3-40e4-b754-04e5b38af2c9',\n",
       " 87: '398cad51-1b59-4738-b410-5ec9340123f8',\n",
       " 88: 'de3a5d41-fbf7-4cfc-93f6-03c4c3f38e5f',\n",
       " 89: '416857b7-001b-42ac-89a4-f8bc3b4dabec',\n",
       " 90: '35f9a04c-8734-4cc0-bff6-bc28a47ff482',\n",
       " 91: '9425e46c-805e-4aa0-8d86-98bf93ab1a8f',\n",
       " 92: 'ff38fe95-a0db-4a67-a90e-f891e45fd7f6',\n",
       " 93: 'eb5b8b03-ad38-496f-8c92-750b6ace2bdf',\n",
       " 94: '6cb97a00-3252-44b8-9ab3-8b6bafad6e49',\n",
       " 95: 'cf37693b-3561-42db-bb5d-252eefc2f424',\n",
       " 96: '58db8caa-c78d-4628-aec7-32ac28c3006e',\n",
       " 97: 'ea89af82-f2d5-4e37-ad0f-37c0020f68ee',\n",
       " 98: '3c540fee-9172-410a-ad43-74ba7e240924',\n",
       " 99: 'c61c7976-910c-421b-8d16-85f76f15ce18',\n",
       " 100: '4779fb6e-1b1a-4bb5-957c-3ffae0fc1194',\n",
       " 101: 'ea792e8e-2514-4e17-8f8c-3531f8dea249',\n",
       " 102: '76ec8c9b-bfa9-4060-8c56-581415261e8f',\n",
       " 103: '6eb31b4d-8f13-4f87-bf5d-234982f76e9d',\n",
       " 104: '55e59fd8-82b6-4125-86ea-3934f688bc1b',\n",
       " 105: '625bedc3-6fd6-4ffd-ad4b-6d66fc019944',\n",
       " 106: '9663d8d8-0b1f-4e74-aedc-04f743e969ba',\n",
       " 107: '79cc7021-90e0-4a94-a6cf-aa3b49b38988',\n",
       " 108: '33f1995f-6620-4310-96d9-c62fb8136412',\n",
       " 109: '6e3bd49e-f476-474a-a5d6-fb0dd13d81ac',\n",
       " 110: '28be68bf-c689-413e-a321-d87aa53294c4',\n",
       " 111: 'b6f41705-6407-49cf-9452-83a039c0e320',\n",
       " 112: '011a6b7c-d8de-496d-9595-f1bd37f68b8e',\n",
       " 113: 'b4323988-b9fb-4df8-b042-95b0b4452857',\n",
       " 114: 'f760f15d-b4d8-441e-a9f8-7847a389b6e7',\n",
       " 115: 'db24ab27-2c7a-41e7-bc59-6d0f88fda638',\n",
       " 116: '3e28a528-e5b5-4e9c-84e1-e2629d61a89b',\n",
       " 117: '0b39f2dc-8e1a-4f4a-bfca-b582ad3b1528',\n",
       " 118: '55a44704-2a5d-44be-88d2-54b8f795fda1',\n",
       " 119: '786cc593-3fb4-4712-af71-a882f7785368',\n",
       " 120: 'bc7b6640-c3cd-4ef1-b10b-eb89f883a57f',\n",
       " 121: 'c9cd238f-1a1f-4308-b458-76590e29233b',\n",
       " 122: '58a9a5a2-9131-482c-9f19-b029395bd219',\n",
       " 123: 'b3bb6cd1-dd58-4389-bd1b-295fcb139188',\n",
       " 124: '425cf852-f661-491c-bf4a-22a7eecc0753',\n",
       " 125: '6d0a7cd6-4078-4a8f-9b0e-eba2d9220ef0',\n",
       " 126: '932e09d9-f236-4126-b8dc-a94467a8d76f',\n",
       " 127: '7d2ea585-929b-4656-96f1-8dfddb3acf52',\n",
       " 128: 'c1278b0a-c86d-4119-a125-4695c64c24a2',\n",
       " 129: '55560aaa-0ecc-4d2f-b45e-bad6e6b7b56c',\n",
       " 130: 'a7ae67c5-e183-4545-b31f-0fcd77f9dfcb',\n",
       " 131: '2d8b76fd-ecb5-4201-9125-2bb47357fe01',\n",
       " 132: '57db1229-07ba-4a48-9840-31381c5aa0e9',\n",
       " 133: '6f219b89-7b0c-4e57-8b31-15ea6a849d76',\n",
       " 134: '03cff630-97d1-4c58-b74f-f021beb25dbe',\n",
       " 135: 'aaeeb1ca-dd84-4c2f-9ab9-d9cf28c077c4',\n",
       " 136: 'd6e1f5ee-b72e-4621-b823-fa5ce845f99f',\n",
       " 137: '1fa82bb3-4640-439b-8942-a53925087e67',\n",
       " 138: '79c4bcc4-2297-432a-9705-3e60f35bf5a5',\n",
       " 139: 'eb48ccec-49ec-42ef-a8f4-b73b187a5373',\n",
       " 140: '1db8b529-8a7c-4e83-aad4-c795831ed010',\n",
       " 141: '6f4543aa-2852-45fc-bb5a-266948e78889',\n",
       " 142: '6073d635-f5b1-4362-a2a1-4d229c48289a',\n",
       " 143: '60032319-fc0f-4c9e-abb4-a676377ce1e2',\n",
       " 144: '797520fa-c09c-4d80-8032-f2b798132b8f',\n",
       " 145: '05092e31-cfd5-416b-b659-11cfe181401a',\n",
       " 146: 'b4470771-afbe-4efa-b136-d3f6013c8bb4',\n",
       " 147: '649e0722-2035-4cf0-a430-04c152221dcc',\n",
       " 148: 'fd60a3e7-4461-4b5d-b59e-d2919d953bb2',\n",
       " 149: '0205e284-6140-497a-9ae0-a80e5e3bec75',\n",
       " 150: '9d49db84-c77f-4aaf-a0bf-b06331653e5f',\n",
       " 151: 'b1f18c87-6dba-4963-b8f4-4deb9ee57808',\n",
       " 152: '1574d23e-384a-4cc9-bcce-99418edc8ca8',\n",
       " 153: 'f1d8fe0b-cecb-4179-9597-9b27c3c41ba0',\n",
       " 154: 'd652c954-b87c-4c33-b35e-dd4bd62bd4c1',\n",
       " 155: 'ccc7d5b3-4ccc-4b44-95fc-ffe335838bba',\n",
       " 156: 'b248f7c3-02f8-432d-a880-fcde3d49265e',\n",
       " 157: '28c79ef9-4848-4e63-a305-2ddb2c22c352',\n",
       " 158: '76576930-536d-4a6a-bbb0-1b95da1d66f7',\n",
       " 159: '87dc772d-7a15-425d-ab46-e413ec05a6ca',\n",
       " 160: 'f33ecfd5-a957-4e60-8831-7ad1630c6e70'}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "# 검색기 불러오기\n",
    "# 직접 db에서 찾아오는 것이 아니라 간단한 호출로 데이터 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Word2Vec'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('Word2Vec에 대해서 알려줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type = 'mmr', search_kwargs = {'k':5, 'lambda_mult':0.25, 'fetch_k':10}\n",
    "    # mmr : 유사성과 다양성을 균형있게 고려하여 검색 결과를 반환하는 검색 방법\n",
    "    # lambda_mult : 0에 가까울 수록 유사성 중시, 1에 가까울 수록 다양성 고려 (기본값 0.5)\n",
    "    # fetch_k 초기 후보 문서 갯수 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Word2Vec'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('Word2Vec에 대해 설명해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Word2Vec')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type = 'mmr', search_kwargs = {'k':2, 'fetch_k':10}\n",
    ")\n",
    "retriever.invoke('Word2Vec에 대해 설명해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Word2Vec'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type = 'similarity_score_threshold', search_kwargs = {'score_threshold':0.8}\n",
    "    # 유사도 점수 기반\n",
    "    # 검색된 문서의 유사도 전수가 기준인 score_threshold 이상일 경우만 결과에 포함\n",
    ")\n",
    "\n",
    "retriever.invoke('Word2Vec에 대해 설명해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs = {'k':1})\n",
    "retriever.invoke('Word2Vec에 대해 설명해줘')\n",
    "# 유사도가 가장 높은값 1개만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.'),\n",
       " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Word2Vec')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs = {'filter': {'source': './nlp-keywords.txt'}, 'k':2})\n",
    "retriever.invoke('Word2Vec에 대해 설명해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bs4.element.SoupStrainer at 0x2cfb9d9a9d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs4.SoupStrainer(\n",
    "    'div',\n",
    "    attrs={'class':['newsct_article _article_body','media_end_head_title']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_path=('https://n.news.naver.com/article/437/0000420199?sid=101'),\n",
    "    bs_kwargs=dict(\n",
    "        # 어떤 조건으로 html 파싱할 것 인지 딕셔너리로 조건 넣어줌\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            'div',\n",
    "            attrs={'class':['newsct_article _article_body','media_end_head_title']}\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents=splits, embedding = OpenAIEmbeddings())\n",
    "# 벡터 db 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "# 검색기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    당신은 질문에 따라 답변을 수행하는 친절한 AI 비서입니다. 당신은 주어진 contect에서 주어진 question에 답하는 것을 수행합니다.\n",
    "    검색된 경과인 다음 context를 사용하여 질문인 question에 답하세요.\n",
    "    만약, context에서 답을 찾을 수 없거나, 답을 모른다면 '주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.'라고 한글로 답변해 주세요.\n",
    "    이름이나 기술적인 용어는 변역하지 않고 그대로 출력해주세요.\n",
    "\n",
    "\n",
    "    # Question : {question},\n",
    "    # Context : {context}\n",
    "    # Answer : \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {'context' : retriever, 'question':RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현대차 그룹이 공개한 산업용 웨어러블 로봇의 이름은 '엑스블 숄더'입니다."
     ]
    }
   ],
   "source": [
    "answer = rag_chain.stream('로봇 이름')\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조끼의 무게는 2kg가 채 되지 않습니다."
     ]
    }
   ],
   "source": [
    "answer = rag_chain.stream('조끼의 무게')\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다."
     ]
    }
   ],
   "source": [
    "answer = rag_chain.stream('로봇 전망')\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
